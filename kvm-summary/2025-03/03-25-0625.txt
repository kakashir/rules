From d1d4c4c4 to 36301c8f
KVM mailing list update from d1d4c4c4 to 36301c8f

Top 15 contributor Email domains (Based on Email Body)

     32 linux.intel.com
     18 amd.com
      5 google.com
      2 linaro.org
      2 intel.com
      1 rosa.ru
      1 alien8.de

Top 15 contributors (Based on Email Body)

     21  Dapeng Mi <dapeng1.mi@linux.intel.com>
      9  Ashish Kalra <ashish.kalra@amd.com>
      8  Kan Liang <kan.liang@linux.intel.com>
      5  Mingwei Zhang <mizhang@google.com>
      4  Manali Shukla <manali.shukla@amd.com>
      3  Xiong Zhang <xiong.y.zhang@linux.intel.com>
      3  Sandipan Das <sandipan.das@amd.com>
      2  Nikunj A Dadhania <nikunj@amd.com>
      2  Dan Carpenter <dan.carpenter@linaro.org>
      1  Xiaoyao Li <xiaoyao.li@intel.com>
      1  Mikhail Lobanov <m.lobanov@rosa.ru>
      1  Chao Gao <chao.gao@intel.com>
      1  "Borislav Petkov (AMD)" <bp@alien8.de>

===== Patch list in this time period =====


===== Patch Commit Messages ====

New:  crypto: ccp: Abort doing SEV INIT if SNP INIT fails
[PATCH v7 1/8] crypto: ccp: Abort doing SEV INIT if SNP INIT fails
Author: Ashish Kalra <Ashish.Kalra@amd.com>


If SNP host support (SYSCFG.SNPEn) is set, then the RMP table must
be initialized before calling SEV INIT.

In other words, if SNP_INIT(_EX) is not issued or fails then
SEV INIT will fail if SNP host support (SYSCFG.SNPEn) is enabled.

Signed-off-by: Ashish Kalra <ashish.kalra@amd.com>
---
 drivers/crypto/ccp/sev-dev.c | 7 ++-----
 1 file changed, 2 insertions(+), 5 deletions(-)

----------------------------------------------------------------------

New:  Move initializing SEV/SNP functionality to KVM
[PATCH v7 0/8] Move initializing SEV/SNP functionality to KVM
Author: Ashish Kalra <Ashish.Kalra@amd.com>


Remove initializing SEV/SNP functionality from PSP driver and instead add
support to KVM to explicitly initialize the PSP if KVM wants to use
SEV/SNP functionality.

This removes SEV/SNP initialization at PSP module probe time and does
on-demand SEV/SNP initialization when KVM really wants to use 
SEV/SNP functionality. This will allow running legacy non-confidential
VMs without initializating SEV functionality. 

The patch-set includes the fix to not continue with SEV INIT if SNP
INIT fails as RMP table must be initialized before calling SEV INIT
if host SNP support is enabled.

This will assist in adding SNP CipherTextHiding support and SEV firmware
hotloading support in KVM without sharing SEV ASID management and SNP
guest context support between PSP driver and KVM and keeping all that
support only in KVM.

To support SEV firmware hotloading, SEV Shutdown will be done explicitly
prior to DOWNLOAD_FIRMWARE_EX and SEV INIT post it to work with the
requirement of SEV to be in UNINIT state for DOWNLOAD_FIRMWARE_EX.
NOTE: SEV firmware hotloading will only be supported if there are no
active SEV/SEV-ES guests. 

v7:
-  Drop the Fixes: tag for patch 01, as continuing with SEV INIT
after SNP INIT(_EX) failure will still cause SEV INIT to fail,
we are simply aborting here after SNP INIT(_EX) failure.
- Fix commit logs.
- Add additional reviewed-by's.

v6:
- Add fix to not continue with SEV INIT if SNP INIT fails as RMP table 
must be initialized before calling SEV INIT if host SNP support is enabled.
- Ensure that for SEV IOCTLs requiring SEV to be initialized, 
_sev_platform_init_locked() is called instead of __sev_platform_init_locked()
to ensure that both implicit SNP and SEV INIT is done for these ioctls and
followed by __sev_firmware_shutdown() to do both SEV and SNP shutdown.
- Refactor doing SEV and SNP INIT implicitly for specific SEV and SNP
ioctls into sev_move_to_init_state() and snp_move_to_init_state(). 
- Ensure correct error code is returned from sev_ioctl_do_pdh_export() 
if platform is not in INIT state.
- Remove dev_info() from sev_pci_init() because this would have printed
a duplicate message.

v5:
- To maintain 1-to-1 mapping between the ioctl commands and the SEV/SNP commands, 
handle the implicit INIT in the same way as SHUTDOWN, which is to use a local error
for INIT and in case of implicit INIT failures, let the error logs from 
__sev_platform_init_locked() OR __sev_snp_init_locked() be printed and always return
INVALID_PLATFORM_STATE as error back to the caller.
- Add better error logging for SEV/SNP INIT and SHUTDOWN commands.
- Fix commit logs.
- Add more acked-by's, reviewed-by's, suggested-by's.

v4:
- Rebase on linux-next which has the fix for SNP broken with kvm_amd
module built-in.
- Fix commit logs.
- Add explicit SEV/SNP initialization and shutdown error logs instead
of using a common exit point.
- Move SEV/SNP shutdown error logs from callers into __sev_platform_shutdown_locked()
and __sev_snp_shutdown_locked().
- Make sure that we continue to support both the probe field and psp_init_on_probe
module parameter for PSP module to support SEV INIT_EX.
- Add reviewed-by's.

v3:
- Move back to do both SNP and SEV platform initialization at KVM module
load time instead of SEV initialization on demand at SEV/SEV-ES VM launch
to prevent breaking QEMU which has a check for SEV to be initialized 
prior to launching SEV/SEV-ES VMs. 
- As both SNP and SEV platform initialization and shutdown is now done at
KVM module load and unload time remove patches for separate SEV and SNP
platform initialization and shutdown.

v2:
- Added support for separate SEV and SNP platform initalization, while
SNP platform initialization is done at KVM module load time, SEV 
platform initialization is done on demand at SEV/SEV-ES VM launch.
- Added support for separate SEV and SNP platform shutdown, both 
SEV and SNP shutdown done at KVM module unload time, only SEV
shutdown down when all SEV/SEV-ES VMs have been destroyed, this
allows SEV firmware hotloading support anytime during system lifetime.
- Updated commit messages for couple of patches in the series with
reference to the feedback received on v1 patches.

Ashish Kalra (8):
  crypto: ccp: Abort doing SEV INIT if SNP INIT fails
  crypto: ccp: Move dev_info/err messages for SEV/SNP init and shutdown
  crypto: ccp: Ensure implicit SEV/SNP init and shutdown in ioctls
  crypto: ccp: Reset TMR size at SNP Shutdown
  crypto: ccp: Register SNP panic notifier only if SNP is enabled
  crypto: ccp: Add new SEV/SNP platform shutdown API
  KVM: SVM: Add support to initialize SEV/SNP functionality in KVM
  crypto: ccp: Move SEV/SNP Platform initialization to KVM

 arch/x86/kvm/svm/sev.c       |  12 ++
 drivers/crypto/ccp/sev-dev.c | 245 +++++++++++++++++++++++++----------
 include/linux/psp-sev.h      |   3 +
 3 files changed, 194 insertions(+), 66 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: forcibly leave SMM mode on vCPU reset
[PATCH] KVM: x86: forcibly leave SMM mode on vCPU reset
Author: Mikhail Lobanov <m.lobanov@rosa.ru>

Previously, commit ed129ec9057f ("KVM: x86: forcibly leave nested mode
on vCPU reset") addressed an issue where a triple fault occurring in
nested mode could lead to use-after-free scenarios. However, the commit
did not handle the analogous situation for System Management Mode (SMM).

This omission results in triggering a WARN when a vCPU reset occurs
while still in SMM mode, due to the check in kvm_vcpu_reset(). This
situation was reprodused using Syzkaller by:
1) Creating a KVM VM and vCPU
2) Sending a KVM_SMI ioctl to explicitly enter SMM
3) Executing invalid instructions causing consecutive exceptions and
eventually a triple fault

The issue manifests as follows:

WARNING: CPU: 0 PID: 25506 at arch/x86/kvm/x86.c:12112
kvm_vcpu_reset+0x1d2/0x1530 arch/x86/kvm/x86.c:12112
Modules linked in:
CPU: 0 PID: 25506 Comm: syz-executor.0 Not tainted
6.1.130-syzkaller-00157-g164fe5dde9b6 #0
Hardware name: QEMU Standard PC (i440FX + PIIX, 1996),
BIOS 1.12.0-1 04/01/2014
RIP: 0010:kvm_vcpu_reset+0x1d2/0x1530 arch/x86/kvm/x86.c:12112
Call Trace:
 <TASK>
 shutdown_interception+0x66/0xb0 arch/x86/kvm/svm/svm.c:2136
 svm_invoke_exit_handler+0x110/0x530 arch/x86/kvm/svm/svm.c:3395
 svm_handle_exit+0x424/0x920 arch/x86/kvm/svm/svm.c:3457
 vcpu_enter_guest arch/x86/kvm/x86.c:10959 [inline]
 vcpu_run+0x2c43/0x5a90 arch/x86/kvm/x86.c:11062
 kvm_arch_vcpu_ioctl_run+0x50f/0x1cf0 arch/x86/kvm/x86.c:11283
 kvm_vcpu_ioctl+0x570/0xf00 arch/x86/kvm/../../../virt/kvm/kvm_main.c:4122
 vfs_ioctl fs/ioctl.c:51 [inline]
 __do_sys_ioctl fs/ioctl.c:870 [inline]
 __se_sys_ioctl fs/ioctl.c:856 [inline]
 __x64_sys_ioctl+0x19a/0x210 fs/ioctl.c:856
 do_syscall_x64 arch/x86/entry/common.c:51 [inline]
 do_syscall_64+0x35/0x80 arch/x86/entry/common.c:81
 entry_SYSCALL_64_after_hwframe+0x6e/0xd8

Considering that hardware CPUs exit SMM mode completely upon receiving
a triple fault by triggering a hardware reset (which inherently leads
to exiting SMM), explicitly perform SMM exit prior to the WARN check.
Although subsequent code clears vCPU hflags, including the SMM flag,
calling kvm_smm_changed ensures the exit from SMM is handled correctly
and explicitly, aligning precisely with hardware behavior.


Found by Linux Verification Center (linuxtesting.org) with Syzkaller.

Fixes: ed129ec9057f ("KVM: x86: forcibly leave nested mode on vCPU reset")
Cc: stable@vger.kernel.org
Signed-off-by: Mikhail Lobanov <m.lobanov@rosa.ru>
---
 arch/x86/kvm/x86.c | 3 +++
 1 file changed, 3 insertions(+)

----------------------------------------------------------------------

New:  perf: Support get/put mediated PMU interfaces
[PATCH v4 01/38] perf: Support get/put mediated PMU interfaces
Author: Mingwei Zhang <mizhang@google.com>


Currently, the guest and host share the PMU resources when a guest is
running. KVM has to create an extra virtual event to simulate the
guest's event, which brings several issues, e.g., high overhead, not
accuracy and etc.

A new mediated PMU method is proposed to address the issue. It requires
that the PMU resources can be fully occupied by the guest while it's
running. Two new interfaces are implemented to fulfill the requirement.
The hypervisor should invoke the interface while creating a guest which
wants the mediated PMU capability.

The PMU resources should only be temporarily occupied as a whole when a
guest is running. When the guest is out, the PMU resources are still
shared among different users.

The exclude_guest event modifier is used to guarantee the exclusive
occupation of the PMU resources. When creating a guest, the hypervisor
should check whether there are !exclude_guest events in the system.
If yes, the creation should fail. Because some PMU resources have been
occupied by other users.
If no, the PMU resources can be safely accessed by the guest directly.
Perf guarantees that no new !exclude_guest events are created when a
guest is running.

Only the mediated PMU is affected, but not for other PMU e.g., uncore
and SW PMU. The behavior of those PMUs are not changed. The guest
enter/exit interfaces should only impact the supported PMUs.
Add a new PERF_PMU_CAP_MEDIATED_VPMU flag to indicate the PMUs that
support the feature.

Add nr_include_guest_events to track the !exclude_guest events of PMU
with PERF_PMU_CAP_MEDIATED_VPMU.

Suggested-by: Sean Christopherson <seanjc@google.com>
Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
Signed-off-by: Mingwei Zhang <mizhang@google.com>
---
 include/linux/perf_event.h | 11 +++++++
 kernel/events/core.c       | 66 ++++++++++++++++++++++++++++++++++++++
 2 files changed, 77 insertions(+)

----------------------------------------------------------------------

New:  Mediated vPMU 4.0 for x86
[PATCH v4 00/38] Mediated vPMU 4.0 for x86
Author: Mingwei Zhang <mizhang@google.com>

With joint effort from the upstream KVM community, we come up with the
4th version of mediated vPMU for x86. We have made the following changes
on top of the previous RFC v3.

v3 -> v4
 - Rebase whole patchset on 6.14-rc3 base.
 - Address Peter's comments on Perf part.
 - Address Sean's comments on KVM part.
   * Change key word "passthrough" to "mediated" in all patches
   * Change static enabling to user space dynamic enabling via KVM_CAP_PMU_CAPABILITY.
   * Only support GLOBAL_CTRL save/restore with VMCS exec_ctrl, drop the MSR
     save/retore list support for GLOBAL_CTRL, thus the support of mediated
     vPMU is constrained to SapphireRapids and later CPUs on Intel side.
   * Merge some small changes into a single patch.
 - Address Sandipan's comment on invalid pmu pointer.
 - Add back "eventsel_hw" and "fixed_ctr_ctrl_hw" to avoid to directly
   manipulate pmc->eventsel and pmu->fixed_ctr_ctrl.


Testing (Intel side):
 - Perf-based legacy vPMU (force emulation on/off)
   * Kselftests pmu_counters_test, pmu_event_filter_test and
     vmx_pmu_caps_test pass.
   * KUT PMU tests pmu, pmu_lbr, pmu_pebs pass.
   * Basic perf counting/sampling tests in 3 scenarios, guest-only,
     host-only and host-guest coexistence all pass.

 - Mediated vPMU (force emulation on/off)
   * Kselftests pmu_counters_test, pmu_event_filter_test and
     vmx_pmu_caps_test pass.
   * KUT PMU tests pmu, pmu_lbr, pmu_pebs pass.
   * Basic perf counting/sampling tests in 3 scenarios, guest-only,
     host-only and host-guest coexistence all pass.

 - Failures. All above tests passed on Intel Granite Rapids as well
   except a failure on KUT/pmu_pebs.
   * GP counter 0 (0xfffffffffffe): PEBS record (written seq 0)
     is verified (including size, counters and cfg).
   * The pebs_data_cfg (0xb500000000) doesn't match with the
     effective MSR_PEBS_DATA_CFG (0x0).
   * This failure has nothing to do with this mediated vPMU patch set. The
     failure is caused by Granite Rapids supported timed PEBS which needs
     extra support on Qemu and KUT/pmu_pebs. These extra support would be
     sent in separate patches later.


Testing (AMD side):
 - Kselftests pmu_counters_test, pmu_event_filter_test and
   vmx_pmu_caps_test all pass

 - legacy guest with KUT/pmu:
   * qmeu option: -cpu host, -perfctr-core
   * when set force_emulation_prefix=1, passes
   * when set force_emulation_prefix=0, passes
 - perfmon-v1 guest with KUT/pmu:
   * qmeu option: -cpu host, -perfmon-v2
   * when set force_emulation_prefix=1, passes
   * when set force_emulation_prefix=0, passes
 - perfmon-v2 guest with KUT/pmu:
   * qmeu option: -cpu host
   * when set force_emulation_prefix=1, passes
   * when set force_emulation_prefix=0, passes

 - perf_fuzzer (perfmon-v2):
   * fails with soft lockup in guest in current version.
   * culprit could be between 6.13 ~ 6.14-rc3 within KVM
   * Series tested on 6.12 and 6.13 without issue.

Note: a QEMU series is needed to run mediated vPMU v4:
 - https://lore.kernel.org/all/20250324123712.34096-1-dapeng1.mi@linux.intel.com/

History:
 - RFC v3: https://lore.kernel.org/all/20240801045907.4010984-1-mizhang@google.com/
 - RFC v2: https://lore.kernel.org/all/20240506053020.3911940-1-mizhang@google.com/
 - RFC v1: https://lore.kernel.org/all/20240126085444.324918-1-xiong.y.zhang@linux.intel.com/


Dapeng Mi (18):
  KVM: x86/pmu: Introduce enable_mediated_pmu global parameter
  KVM: x86/pmu: Check PMU cpuid configuration from user space
  KVM: x86: Rename vmx_vmentry/vmexit_ctrl() helpers
  KVM: x86/pmu: Add perf_capabilities field in struct kvm_host_values{}
  KVM: x86/pmu: Move PMU_CAP_{FW_WRITES,LBR_FMT} into msr-index.h header
  KVM: VMX: Add macros to wrap around
    {secondary,tertiary}_exec_controls_changebit()
  KVM: x86/pmu: Check if mediated vPMU can intercept rdpmc
  KVM: x86/pmu/vmx: Save/load guest IA32_PERF_GLOBAL_CTRL with
    vm_exit/entry_ctrl
  KVM: x86/pmu: Optimize intel/amd_pmu_refresh() helpers
  KVM: x86/pmu: Setup PMU MSRs' interception mode
  KVM: x86/pmu: Handle PMU MSRs interception and event filtering
  KVM: x86/pmu: Switch host/guest PMU context at vm-exit/vm-entry
  KVM: x86/pmu: Handle emulated instruction for mediated vPMU
  KVM: nVMX: Add macros to simplify nested MSR interception setting
  KVM: selftests: Add mediated vPMU supported for pmu tests
  KVM: Selftests: Support mediated vPMU for vmx_pmu_caps_test
  KVM: Selftests: Fix pmu_counters_test error for mediated vPMU
  KVM: x86/pmu: Expose enable_mediated_pmu parameter to user space

Kan Liang (8):
  perf: Support get/put mediated PMU interfaces
  perf: Skip pmu_ctx based on event_type
  perf: Clean up perf ctx time
  perf: Add a EVENT_GUEST flag
  perf: Add generic exclude_guest support
  perf: Add switch_guest_ctx() interface
  perf/x86: Support switch_guest_ctx interface
  perf/x86/intel: Support PERF_PMU_CAP_MEDIATED_VPMU

Mingwei Zhang (5):
  perf/x86: Forbid PMI handler when guest own PMU
  perf/x86/core: Plumb mediated PMU capability from x86_pmu to
    x86_pmu_cap
  KVM: x86/pmu: Exclude PMU MSRs in vmx_get_passthrough_msr_slot()
  KVM: x86/pmu: introduce eventsel_hw to prepare for pmu event filtering
  KVM: nVMX: Add nested virtualization support for mediated PMU

Sandipan Das (4):
  perf/x86/core: Do not set bit width for unavailable counters
  KVM: x86/pmu: Add AMD PMU registers to direct access list
  KVM: x86/pmu/svm: Set GuestOnly bit and clear HostOnly bit when guest
    write to event selectors
  perf/x86/amd: Support PERF_PMU_CAP_MEDIATED_VPMU for AMD host

Xiong Zhang (3):
  x86/irq: Factor out common code for installing kvm irq handler
  perf: core/x86: Register a new vector for KVM GUEST PMI
  KVM: x86/pmu: Register KVM_GUEST_PMI_VECTOR handler

 arch/x86/events/amd/core.c                    |   2 +
 arch/x86/events/core.c                        |  40 +-
 arch/x86/events/intel/core.c                  |   5 +
 arch/x86/include/asm/hardirq.h                |   1 +
 arch/x86/include/asm/idtentry.h               |   1 +
 arch/x86/include/asm/irq.h                    |   2 +-
 arch/x86/include/asm/irq_vectors.h            |   5 +-
 arch/x86/include/asm/kvm-x86-pmu-ops.h        |   2 +
 arch/x86/include/asm/kvm_host.h               |  10 +
 arch/x86/include/asm/msr-index.h              |  18 +-
 arch/x86/include/asm/perf_event.h             |   1 +
 arch/x86/include/asm/vmx.h                    |   1 +
 arch/x86/kernel/idt.c                         |   1 +
 arch/x86/kernel/irq.c                         |  39 +-
 arch/x86/kvm/cpuid.c                          |  15 +
 arch/x86/kvm/pmu.c                            | 254 ++++++++-
 arch/x86/kvm/pmu.h                            |  45 ++
 arch/x86/kvm/svm/pmu.c                        | 148 ++++-
 arch/x86/kvm/svm/svm.c                        |  26 +
 arch/x86/kvm/svm/svm.h                        |   2 +-
 arch/x86/kvm/vmx/capabilities.h               |  11 +-
 arch/x86/kvm/vmx/nested.c                     |  68 ++-
 arch/x86/kvm/vmx/pmu_intel.c                  | 224 ++++++--
 arch/x86/kvm/vmx/vmx.c                        |  89 +--
 arch/x86/kvm/vmx/vmx.h                        |  11 +-
 arch/x86/kvm/x86.c                            |  63 ++-
 arch/x86/kvm/x86.h                            |   2 +
 include/linux/perf_event.h                    |  47 +-
 kernel/events/core.c                          | 519 ++++++++++++++----
 .../beauty/arch/x86/include/asm/irq_vectors.h |   5 +-
 .../selftests/kvm/include/kvm_test_harness.h  |  13 +
 .../testing/selftests/kvm/include/kvm_util.h  |   3 +
 .../selftests/kvm/include/x86/processor.h     |   8 +
 tools/testing/selftests/kvm/lib/kvm_util.c    |  23 +
 .../selftests/kvm/x86/pmu_counters_test.c     |  24 +-
 .../selftests/kvm/x86/pmu_event_filter_test.c |   8 +-
 .../selftests/kvm/x86/vmx_pmu_caps_test.c     |   2 +-
 37 files changed, 1480 insertions(+), 258 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: Sort CPUID_8000_0021_EAX leaf bits properly
[PATCH] KVM: x86: Sort CPUID_8000_0021_EAX leaf bits properly
Author: Borislav Petkov <bp@kernel.org>


WRMSR_XX_BASE_NS is bit 1 so put it there, add some new bits as
comments only.

Signed-off-by: Borislav Petkov (AMD) <bp@alien8.de>
---
 arch/x86/kvm/cpuid.c | 7 ++++++-
 1 file changed, 6 insertions(+), 1 deletion(-)

----------------------------------------------------------------------

New:  KVM: VMX: Flush shadow VMCS on emergency reboot
[PATCH] KVM: VMX: Flush shadow VMCS on emergency reboot
Author: Chao Gao <chao.gao@intel.com>

Ensure the shadow VMCS cache is evicted during an emergency reboot to
prevent potential memory corruption if the cache is evicted after reboot.

This issue was identified through code inspection, as __loaded_vmcs_clear()
flushes both the normal VMCS and the shadow VMCS.

Avoid checking the "launched" state during an emergency reboot, unlike the
behavior in __loaded_vmcs_clear(). This is important because reboot NMIs
can interfere with operations like copy_shadow_to_vmcs12(), where shadow
VMCSes are loaded directly using VMPTRLD. In such cases, if NMIs occur
right after the VMCS load, the shadow VMCSes will be active but the
"launched" state may not be set.

Signed-off-by: Chao Gao <chao.gao@intel.com>
---
 arch/x86/kvm/vmx/vmx.c | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

----------------------------------------------------------------------

New:  Add support for the Bus Lock Threshold
[PATCH v4 0/5] Add support for the Bus Lock Threshold
Author: Manali Shukla <manali.shukla@amd.com>

Misbehaving guests can cause bus locks to degrade the performance of
a system. Non-WB (write-back) and misaligned locked RMW (read-modify-write)
instructions are referred to as "bus locks" and require system wide
synchronization among all processors to guarantee the atomicity. The bus
locks can impose notable performance penalties for all processors within
the system.

Support for the Bus Lock Threshold is indicated by CPUID
Fn8000_000A_EDX[29] BusLockThreshold=1, the VMCB provides a Bus Lock
Threshold enable bit and an unsigned 16-bit Bus Lock Threshold count.

VMCB intercept bit
    VMCB Offset     Bits    Function
    14h             5       Intercept bus lock operations

Bus lock threshold count
    VMCB Offset     Bits    Function
    120h            15:0    Bus lock counter

During VMRUN, the bus lock threshold count is fetched and stored in an
internal count register.  Prior to executing a bus lock within the guest,
the processor verifies the count in the bus lock register. If the count is
greater than zero, the processor executes the bus lock, reducing the count.
However, if the count is zero, the bus lock operation is not performed, and
instead, a Bus Lock Threshold #VMEXIT is triggered to transfer control to
the Virtual Machine Monitor (VMM).

A Bus Lock Threshold #VMEXIT is reported to the VMM with VMEXIT code 0xA5h,
VMEXIT_BUSLOCK. EXITINFO1 and EXITINFO2 are set to 0 on a VMEXIT_BUSLOCK.
On a #VMEXIT, the processor writes the current value of the Bus Lock
Threshold Counter to the VMCB.

Note: Currently, virtualizing the Bus Lock Threshold feature for L1 guest is
not supported.

More details about the Bus Lock Threshold feature can be found in AMD APM
[1].

v3 -> v4
- Incorporated Sean's review comments
  - Added a preparatory patch to move linear_rip out of kvm_pio_request, so
    that it can be used by the bus lock threshold patches.
  - Added complete_userspace_buslock() function to reload bus_lock_counter
    to '1' only if the usespace has not changed the RIP.
  - Added changes to continue running bus_lock_counter accross the nested
    transitions. 

v2 -> v3
- Drop parch to add virt tag in /proc/cpuinfo.
- Incorporated Tom's review comments.

v1 -> v2
- Incorporated misc review comments from Sean.
- Removed bus_lock_counter module parameter.
- Set the value of bus_lock_counter to zero by default and reload the value by 1
  in bus lock exit handler.
- Add documentation for the behavioral difference for KVM_EXIT_BUS_LOCK.
- Improved selftest for buslock to work on SVM and VMX.
- Rewrite the commit messages.

Patches are prepared on kvm-next/next (c9ea48bb6ee6).

Testing done:
- Tested the Bus Lock Threshold functionality on normal, SEV, SEV-ES and SEV-SNP guests.
- Tested the Bus Lock Threshold functionality on nested guests.

v1: https://lore.kernel.org/kvm/20240709175145.9986-4-manali.shukla@amd.com/T/
v2: https://lore.kernel.org/kvm/20241001063413.687787-4-manali.shukla@amd.com/T/
v3: https://lore.kernel.org/kvm/20241004053341.5726-1-manali.shukla@amd.com/T/

[1]: AMD64 Architecture Programmer's Manual Pub. 24593, April 2024,
     Vol 2, 15.14.5 Bus Lock Threshold.
     https://bugzilla.kernel.org/attachment.cgi?id=306250

Manali Shukla (3):
  KVM: x86: Preparatory patch to move linear_rip out of kvm_pio_request
  x86/cpufeatures: Add CPUID feature bit for the Bus Lock Threshold
  KVM: SVM: Add support for KVM_CAP_X86_BUS_LOCK_EXIT on SVM CPUs

Nikunj A Dadhania (2):
  KVM: SVM: Enable Bus lock threshold exit
  KVM: selftests: Add bus lock exit test

 Documentation/virt/kvm/api.rst                |  19 +++
 arch/x86/include/asm/cpufeatures.h            |   1 +
 arch/x86/include/asm/kvm_host.h               |   2 +-
 arch/x86/include/asm/svm.h                    |   5 +-
 arch/x86/include/uapi/asm/svm.h               |   2 +
 arch/x86/kvm/svm/nested.c                     |  42 ++++++
 arch/x86/kvm/svm/svm.c                        |  38 +++++
 arch/x86/kvm/svm/svm.h                        |   2 +
 arch/x86/kvm/x86.c                            |   8 +-
 tools/testing/selftests/kvm/Makefile.kvm      |   1 +
 .../selftests/kvm/x86/kvm_buslock_test.c      | 135 ++++++++++++++++++
 11 files changed, 249 insertions(+), 6 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: Preparatory patch to move linear_rip out of kvm_pio_request
[PATCH v4 1/5] KVM: x86: Preparatory patch to move linear_rip out of kvm_pio_request
Author: Manali Shukla <manali.shukla@amd.com>

Add a refactoring prep patch to move linear_rip out of kvm_pio_request
and place it next to complete_userspace_io.  There's nothing port I/O
specific about linear_rip field, it just so happens to that port I/O is the
only case where KVM's ABI is to let userspace stuff state (to emulate
RESET) without first completing the I/O instruction.

No functional changes intended.

Suggested-by: Sean Christopherson <seanjc@google.com>
Signed-off-by: Manali Shukla <manali.shukla@amd.com>
---
 arch/x86/include/asm/kvm_host.h | 2 +-
 arch/x86/kvm/x86.c              | 8 ++++----
 2 files changed, 5 insertions(+), 5 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: clean up a return
[PATCH] KVM: x86: clean up a return
Author: Dan Carpenter <dan.carpenter@linaro.org>

Returning a literal X86EMUL_CONTINUE is slightly clearer than returning
rc.

Signed-off-by: Dan Carpenter <dan.carpenter@linaro.org>
---
 arch/x86/kvm/x86.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

----------------------------------------------------------------------

New:  kvm: Introduce kvm_arch_pre_create_vcpu()
[PATCH 1/3] kvm: Introduce kvm_arch_pre_create_vcpu()
Author: Dapeng Mi <dapeng1.mi@linux.intel.com>


Introduce kvm_arch_pre_create_vcpu(), to perform arch-dependent
work prior to create any vcpu. This is for i386 TDX because it needs
call TDX_INIT_VM before creating any vcpu.

The specific implemnet of i386 will be added in the future patch.

Signed-off-by: Xiaoyao Li <xiaoyao.li@intel.com>
Acked-by: Gerd Hoffmann <kraxel@redhat.com>
---
 accel/kvm/kvm-all.c        | 5 +++++
 include/system/kvm.h       | 1 +
 target/arm/kvm.c           | 5 +++++
 target/i386/kvm/kvm.c      | 5 +++++
 target/loongarch/kvm/kvm.c | 5 +++++
 target/mips/kvm.c          | 5 +++++
 target/ppc/kvm.c           | 5 +++++
 target/riscv/kvm/kvm-cpu.c | 5 +++++
 target/s390x/kvm/kvm.c     | 5 +++++
 9 files changed, 41 insertions(+)

----------------------------------------------------------------------

New:  Enable x86 mediated vPMU
[PATCH 0/3] Enable x86 mediated vPMU
Author: Dapeng Mi <dapeng1.mi@linux.intel.com>

This small patch series enables the newly introduced KVM x86 mediated
vPMU solution. As KVM maintainer's suggestion, KVM mediated vPMU is
disabled by default unless user explicitly calls KVM_CAP_PMU_CAPABILITY
ioctl to enable it.

As for mediated vPMU, it's a new pass-through vPMU solution which is
designed to replace the legacy perf-based vPMU which has several
drawbacks, such as high performance overhead, hard to support new PMU
features, etc. Most of PMU MSRs except EVENTSELx are passed through to
guest in mediated vPMU. Currently the latest mediated vPMU patch series
is v3[1], the v4 patchset would be sent soon.

In this series, patch 1/3 introduces a helper
kvm_arch_pre_create_vcpu() which would be called before creating vCPU.
This patch comes from Xiaoyao's "QEMU TDX support" patchset[2]. Patch
2/3 leverages the patch 1/3 introduced helper to call
KVM_CAP_PMU_CAPABILITY ioctl to enable/disable KVM vPMU (mediated vPMU).
This patch is similar with patch 4/10 of Dongli's
"target/i386/kvm/pmu: PMU Enhancement, Bugfix and Cleanup" patchset[3],
but can be considered as an enhanced version. Patch 3/3 provides support
for newly introduced VMCS bit SAVE_IA32_PERF_GLOBAL_CTRL.

Tests:
  * Tests on Sapphire Rapids platform, both mediated vPMU and legacy
    perf-based vPMU can be enabled/disabled with "+/-pmu" option.

Ref:
[1] https://lore.kernel.org/all/20240801045907.4010984-1-mizhang@google.com/
[2] https://lore.kernel.org/all/20250124132048.3229049-8-xiaoyao.li@intel.com/
[3] https://lore.kernel.org/all/20250302220112.17653-5-dongli.zhang@oracle.com/  

Dapeng Mi (2):
  target/i386: Call KVM_CAP_PMU_CAPABILITY iotcl to enable/disable PMU
  target/i386: Support VMX_VM_EXIT_SAVE_IA32_PERF_GLOBAL_CTRL

Xiaoyao Li (1):
  kvm: Introduce kvm_arch_pre_create_vcpu()

 accel/kvm/kvm-all.c        |  5 +++++
 include/system/kvm.h       |  1 +
 target/arm/kvm.c           |  5 +++++
 target/i386/cpu.c          | 12 ++++++++----
 target/i386/cpu.h          |  1 +
 target/i386/kvm/kvm.c      | 22 ++++++++++++++++++++++
 target/loongarch/kvm/kvm.c |  5 +++++
 target/mips/kvm.c          |  5 +++++
 target/ppc/kvm.c           |  5 +++++
 target/riscv/kvm/kvm-cpu.c |  5 +++++
 target/s390x/kvm/kvm.c     |  5 +++++
 11 files changed, 67 insertions(+), 4 deletions(-)

----------------------------------------------------------------------

