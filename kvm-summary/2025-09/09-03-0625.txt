From 131572024 to f97beb70c
KVM mailing list update from 131572024 to f97beb70c

Top 15 contributor Email domains (Based on Email Body)

     30 kernel.org
      5 loongson.cn
      4 tu-dortmund.de
      3 huawei.com
      2 amazon.com=0A=
      2 amazon.com
      1 gmail.com
      1 amd.com
      1 amazon.co.uk

Top 15 contributors (Based on Email Body)

     30  Mark Brown <broonie@kernel.org>
      5  Bibo Mao <maobibo@loongson.cn>
      4  Simon Schippers <simon.schippers@tu-dortmund.de>
      3  Longfang Liu <liulongfang@huawei.com>
      2  Nikita Kalyazin <kalyazin@amazon.com>=0A=
      2  Aqib Faruqui <aqibaf@amazon.com>
      1  Shivank Garg <shivankg@amd.com>
      1  Ranganath V N <vnranganath.20@gmail.com>
      1  "Kalyazin, Nikita" <kalyazin@amazon.co.uk>

===== Patch list in this time period =====


===== Patch Commit Messages ====

New:  Documentation: Fix spelling mistakes
[PATCH] Documentation: Fix spelling mistakes
Author: Ranganath V N <vnranganath.20@gmail.com>

Corrected a few spelling mistakes to improve the readability.

Signed-off-by: Ranganath V N <vnranganath.20@gmail.com>
---
 Documentation/devicetree/bindings/submitting-patches.rst | 2 +-
 Documentation/filesystems/iomap/operations.rst           | 2 +-
 Documentation/virt/kvm/review-checklist.rst              | 2 +-
 3 files changed, 3 insertions(+), 3 deletions(-)

----------------------------------------------------------------------

New:  arm64/sysreg: Update SMIDR_EL1 to DDI0601 2025-06
[PATCH v8 01/29] arm64/sysreg: Update SMIDR_EL1 to DDI0601 2025-06
Author: Mark Brown <broonie@kernel.org>

Update the definiton of SMIDR_EL1 in the sysreg definition to reflect the
information in DD0601 2025-06. This includes somewhat more generic ways of
describing the sharing of SMCUs, more information on supported priorities
and provides additional resolution for describing affinity groups.

Signed-off-by: Mark Brown <broonie@kernel.org>
---
 arch/arm64/tools/sysreg | 8 ++++++--
 1 file changed, 6 insertions(+), 2 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: Implement support for SME
[PATCH v8 00/29] KVM: arm64: Implement support for SME
Author: Mark Brown <broonie@kernel.org>

I've removed the RFC tag from this version of the series, but the items
that I'm looking for feedback on remains the same:

 - The userspace ABI, in particular:
  - The vector length used for the SVE registers, access to the SVE
    registers and access to ZA and (if available) ZT0 depending on
    the current state of PSTATE.{SM,ZA}.
  - The use of a single finalisation for both SVE and SME.

 - The addition of control for enabling fine grained traps in a similar
   manner to FGU but without the UNDEF, I'm not clear if this is desired
   at all and at present this requires symmetric read and write traps like
   FGU. That seemed like it might be desired from an implementation
   point of view but we already have one case where we enable an
   asymmetric trap (for ARM64_WORKAROUND_AMPERE_AC03_CPU_38) and it
   seems generally useful to enable asymmetrically.

This series implements support for SME use in non-protected KVM guests.
Much of this is very similar to SVE, the main additional challenge that
SME presents is that it introduces a new vector length similar to the
SVE vector length and two new controls which change the registers seen
by guests:

 - PSTATE.ZA enables the ZA matrix register and, if SME2 is supported,
   the ZT0 LUT register.
 - PSTATE.SM enables streaming mode, a new floating point mode which
   uses the SVE register set with the separately configured SME vector
   length.  In streaming mode implementation of the FFR register is
   optional.

It is also permitted to build systems which support SME without SVE, in
this case when not in streaming mode no SVE registers or instructions
are available.  Further, there is no requirement that there be any
overlap in the set of vector lengths supported by SVE and SME in a
system, this is expected to be a common situation in practical systems.

Since there is a new vector length to configure we introduce a new
feature parallel to the existing SVE one with a new pseudo register for
the streaming mode vector length.  Due to the overlap with SVE caused by
streaming mode rather than finalising SME as a separate feature we use
the existing SVE finalisation to also finalise SME, a new define
KVM_ARM_VCPU_VEC is provided to help make user code clearer.  Finalising
SVE and SME separately would introduce complication with register access
since finalising SVE makes the SVE registers writeable by userspace and
doing multiple finalisations results in an error being reported.
Dealing with a state where the SVE registers are writeable due to one of
SVE or SME being finalised but may have their VL changed by the other
being finalised seems like needless complexity with minimal practical
utility, it seems clearer to just express directly that only one
finalisation can be done in the ABI.

Access to the floating point registers follows the architecture:

 - When both SVE and SME are present:
   - If PSTATE.SM == 0 the vector length used for the Z and P registers
     is the SVE vector length.
   - If PSTATE.SM == 1 the vector length used for the Z and P registers
     is the SME vector length.
 - If only SME is present:
   - If PSTATE.SM == 0 the Z and P registers are inaccessible and the
     floating point state accessed via the encodings for the V registers.
   - If PSTATE.SM == 1 the vector length used for the Z and P registers
 - The SME specific ZA and ZT0 registers are only accessible if SVCR.ZA is 1.

The VMM must understand this, in particular when loading state SVCR
should be configured before other state.  It should be noted that while
the architecture refers to PSTATE.SM and PSTATE.ZA these PSTATE bits are
not preserved in SPSR_ELx, they are only accessible via SVCR.

There are a large number of subfeatures for SME, most of which only
offer additional instructions but some of which (SME2 and FA64) add
architectural state. These are configured via the ID registers as per
usual.

Protected KVM supported, with the implementation maintaining the
existing restriction that the hypervisor will refuse to run if streaming
mode or ZA is enabled.  This both simplfies the code and avoids the need
to allocate storage for host ZA and ZT0 state, there seems to be little
practical use case for supporting this and the memory usage would be
non-trivial.

The new KVM_ARM_VCPU_VEC feature and ZA and ZT0 registers have not been
added to the get-reg-list selftest, the idea of supporting additional
features there without restructuring the program to generate all
possible feature combinations has been rejected.  I will post a separate
series which does that restructuring.

Signed-off-by: Mark Brown <broonie@kernel.org>
---
Changes in v8:
- Small fixes in ABI documentation.
- Link to v7: https://lore.kernel.org/r/20250822-kvm-arm64-sme-v7-0-7a65d82b8b10@kernel.org

Changes in v7:
- Rebase onto v6.17-rc1.
- Handle SMIDR_EL1 as a VM wide ID register and use this in feat_sme_smps().
- Expose affinity fields in SMIDR_EL1.
- Remove SMPRI_EL1 from vcpu_sysreg, the value is always 0 currently.
- Prevent userspace writes to SMPRIMAP_EL2.
- Link to v6: https://lore.kernel.org/r/20250625-kvm-arm64-sme-v6-0-114cff4ffe04@kernel.org

Changes in v6:
- Rebase onto v6.16-rc3.
- Link to v5: https://lore.kernel.org/r/20250417-kvm-arm64-sme-v5-0-f469a2d5f574@kernel.org

Changes in v5:
- Rebase onto v6.15-rc2.
- Add pKVM guest support.
- Always restore SVCR.
- Link to v4: https://lore.kernel.org/r/20250214-kvm-arm64-sme-v4-0-d64a681adcc2@kernel.org

Changes in v4:
- Rebase onto v6.14-rc2 and Mark Rutland's fixes.
- Expose SME to nested guests.
- Additional cleanups and test fixes following on from the rebase.
- Flush register state on VMM PSTATE.{SM,ZA}.
- Link to v3: https://lore.kernel.org/r/20241220-kvm-arm64-sme-v3-0-05b018c1ffeb@kernel.org

Changes in v3:
- Rebase onto v6.12-rc2.
- Link to v2: https://lore.kernel.org/r/20231222-kvm-arm64-sme-v2-0-da226cb180bb@kernel.org

Changes in v2:
- Rebase onto v6.7-rc3.
- Configure subfeatures based on host system only.
- Complete nVHE support.
- There was some snafu with sending v1 out, it didn't make it to the
  lists but in case it hit people's inboxes I'm sending as v2.

---
Mark Brown (29):
      arm64/sysreg: Update SMIDR_EL1 to DDI0601 2025-06
      arm64/fpsimd: Update FA64 and ZT0 enables when loading SME state
      arm64/fpsimd: Decide to save ZT0 and streaming mode FFR at bind time
      arm64/fpsimd: Check enable bit for FA64 when saving EFI state
      arm64/fpsimd: Determine maximum virtualisable SME vector length
      KVM: arm64: Introduce non-UNDEF FGT control
      KVM: arm64: Pay attention to FFR parameter in SVE save and load
      KVM: arm64: Pull ctxt_has_ helpers to start of sysreg-sr.h
      KVM: arm64: Move SVE state access macros after feature test macros
      KVM: arm64: Rename SVE finalization constants to be more general
      KVM: arm64: Document the KVM ABI for SME
      KVM: arm64: Define internal features for SME
      KVM: arm64: Rename sve_state_reg_region
      KVM: arm64: Store vector lengths in an array
      KVM: arm64: Implement SME vector length configuration
      KVM: arm64: Support SME control registers
      KVM: arm64: Support TPIDR2_EL0
      KVM: arm64: Support SME identification registers for guests
      KVM: arm64: Support SME priority registers
      KVM: arm64: Provide assembly for SME register access
      KVM: arm64: Support userspace access to streaming mode Z and P registers
      KVM: arm64: Flush register state on writes to SVCR.SM and SVCR.ZA
      KVM: arm64: Expose SME specific state to userspace
      KVM: arm64: Context switch SME state for guests
      KVM: arm64: Handle SME exceptions
      KVM: arm64: Expose SME to nested guests
      KVM: arm64: Provide interface for configuring and enabling SME for guests
      KVM: arm64: selftests: Add SME system registers to get-reg-list
      KVM: arm64: selftests: Add SME to set_id_regs test

 Documentation/virt/kvm/api.rst                   | 115 ++++++++---
 arch/arm64/include/asm/fpsimd.h                  |  26 +++
 arch/arm64/include/asm/kvm_emulate.h             |   6 +
 arch/arm64/include/asm/kvm_host.h                | 169 ++++++++++++---
 arch/arm64/include/asm/kvm_hyp.h                 |   5 +-
 arch/arm64/include/asm/kvm_pkvm.h                |   2 +-
 arch/arm64/include/asm/vncr_mapping.h            |   2 +
 arch/arm64/include/uapi/asm/kvm.h                |  33 +++
 arch/arm64/kernel/cpufeature.c                   |   2 -
 arch/arm64/kernel/fpsimd.c                       |  89 ++++----
 arch/arm64/kvm/arm.c                             |  10 +
 arch/arm64/kvm/config.c                          |   8 +-
 arch/arm64/kvm/fpsimd.c                          |  28 ++-
 arch/arm64/kvm/guest.c                           | 252 ++++++++++++++++++++---
 arch/arm64/kvm/handle_exit.c                     |  14 ++
 arch/arm64/kvm/hyp/fpsimd.S                      |  28 ++-
 arch/arm64/kvm/hyp/include/hyp/switch.h          | 175 ++++++++++++++--
 arch/arm64/kvm/hyp/include/hyp/sysreg-sr.h       | 110 ++++++----
 arch/arm64/kvm/hyp/nvhe/hyp-main.c               |  86 ++++++--
 arch/arm64/kvm/hyp/nvhe/pkvm.c                   |  85 ++++++--
 arch/arm64/kvm/hyp/nvhe/switch.c                 |   4 +-
 arch/arm64/kvm/hyp/nvhe/sys_regs.c               |   6 +
 arch/arm64/kvm/hyp/vhe/switch.c                  |  17 +-
 arch/arm64/kvm/hyp/vhe/sysreg-sr.c               |   7 +
 arch/arm64/kvm/nested.c                          |   3 +-
 arch/arm64/kvm/reset.c                           | 156 ++++++++++----
 arch/arm64/kvm/sys_regs.c                        | 141 ++++++++++++-
 arch/arm64/tools/sysreg                          |   8 +-
 include/uapi/linux/kvm.h                         |   1 +
 tools/testing/selftests/kvm/arm64/get-reg-list.c |  15 +-
 tools/testing/selftests/kvm/arm64/set_id_regs.c  |  27 ++-
 31 files changed, 1327 insertions(+), 303 deletions(-)

----------------------------------------------------------------------

New:  KVM: guest_memfd: add generic population via write
[PATCH v5 1/2] KVM: guest_memfd: add generic population via write
Author: Kalyazin, Nikita <kalyazin@amazon.co.uk>

=0A=
write syscall populates guest_memfd with user-supplied data in a generic=0A=
way, ie no vendor-specific preparation is performed.  This is supposed=0A=
to be used in non-CoCo setups where guest memory is not=0A=
hardware-encrypted.=0A=
=0A=
The following behaviour is implemented:=0A=
 - only page-aligned count and offset are allowed=0A=
 - if the memory is already allocated, the call will successfully=0A=
   populate it=0A=
 - if the memory is not allocated, the call will both allocate and=0A=
   populate=0A=
 - if the memory is already populated, the call will not repopulate it=0A=
=0A=
Signed-off-by: Nikita Kalyazin <kalyazin@amazon.com>=0A=
---=0A=
 virt/kvm/guest_memfd.c | 64 +++++++++++++++++++++++++++++++++++++++++-=0A=
 1 file changed, 63 insertions(+), 1 deletion(-)=0A=

----------------------------------------------------------------------

New:  KVM: guest_memfd: use write for population
[PATCH v5 0/2] KVM: guest_memfd: use write for population
Author: Kalyazin, Nikita <kalyazin@amazon.co.uk>

[ based on kvm/next ]=0A=
=0A=
Implement guest_memfd allocation and population via the write syscall.=0A=
This is useful in non-CoCo use cases where the host can access guest=0A=
memory.  Even though the same can also be achieved via userspace mapping=0A=
and memcpying from userspace, write provides a more performant option=0A=
because it does not need to set page tables and it does not cause a page=0A=
fault for every page like memcpy would.  Note that memcpy cannot be=0A=
accelerated via MADV_POPULATE_WRITE as it is  not supported by=0A=
guest_memfd and relies on GUP.=0A=
=0A=
Populating 512MiB of guest_memfd on a x86 machine:=0A=
 - via memcpy: 436 ms=0A=
 - via write:  202 ms (-54%)=0A=
=0A=
v5:=0A=
 - Replace the call to the unexported filemap_remove_folio with=0A=
   zeroing the bytes that could not be copied=0A=
 - Fix checkpatch findings=0A=
=0A=
v4:=0A=
 - https://lore.kernel.org/kvm/20250828153049.3922-1-kalyazin@amazon.com=0A=
 - Switch from implementing the write callback to write_iter=0A=
 - Remove conditional compilation=0A=
=0A=
v3:=0A=
 - https://lore.kernel.org/kvm/20250303130838.28812-1-kalyazin@amazon.com=
=0A=
 - David/Mike D: Only compile support for the write syscall if=0A=
   CONFIG_KVM_GMEM_SHARED_MEM (now gone) is enabled.=0A=
v2:=0A=
 - https://lore.kernel.org/kvm/20241129123929.64790-1-kalyazin@amazon.com=
=0A=
 - Switch from an ioctl to the write syscall to implement population=0A=
=0A=
v1:=0A=
 - https://lore.kernel.org/kvm/20241024095429.54052-1-kalyazin@amazon.com=
=0A=
=0A=
Nikita Kalyazin (2):=0A=
  KVM: guest_memfd: add generic population via write=0A=
  KVM: selftests: update guest_memfd write tests=0A=
=0A=
 .../testing/selftests/kvm/guest_memfd_test.c  | 86 +++++++++++++++++--=0A=
 virt/kvm/guest_memfd.c                        | 62 ++++++++++++-=0A=
 2 files changed, 141 insertions(+), 7 deletions(-)=0A=

----------------------------------------------------------------------

New:  Move copy_from_user out of preempt disabled context
[PATCH 0/4] Move copy_from_user out of preempt disabled context
Author: Bibo Mao <maobibo@loongson.cn>

Function copy_from_user() and copy_to_user() may sleep because of page
fault, and they cannot be called with preempt disabled context, such as
spin_lock hold context.

Here this patch set move copy_from_user out of preempt disabled context,
local variable is added in spinlock context at first and then put to user
memory from local variable without spinlock.

Bibo Mao (4):
  LoongArch: KVM: Avoid use copy_from_user with lock hold in
    kvm_eiointc_regs_access
  LoongArch: KVM: Avoid use copy_from_user with lock hold in
    kvm_eiointc_sw_status_access
  LoongArch: KVM: Avoid use copy_from_user with lock hold in
    kvm_eiointc_ctrl_access
  LoongArch: KVM: Avoid use copy_from_user with lock hold in
    kvm_pch_pic_regs_access

 arch/loongarch/kvm/intc/eiointc.c | 87 +++++++++++++++++++------------
 arch/loongarch/kvm/intc/pch_pic.c | 22 +++++---
 2 files changed, 68 insertions(+), 41 deletions(-)

----------------------------------------------------------------------

New:  LoongArch: KVM: Avoid use copy_from_user with lock hold in kvm_eiointc_regs_access
[PATCH 1/4] LoongArch: KVM: Avoid use copy_from_user with lock hold in kvm_eiointc_regs_access
Author: Bibo Mao <maobibo@loongson.cn>

Function copy_from_user() and copy_to_user() may sleep because of page
fault, and they cannot be called in spin_lock hold context. Otherwise there
will be possible warning such as:

BUG: sleeping function called from invalid context at include/linux/uaccess.h:192
in_atomic(): 1, irqs_disabled(): 1, non_block: 0, pid: 6292, name: qemu-system-loo
preempt_count: 1, expected: 0
RCU nest depth: 0, expected: 0
INFO: lockdep is turned off.
irq event stamp: 0
hardirqs last  enabled at (0): [<0000000000000000>] 0x0
hardirqs last disabled at (0): [<9000000004c4a554>] copy_process+0x90c/0x1d40
softirqs last  enabled at (0): [<9000000004c4a554>] copy_process+0x90c/0x1d40
softirqs last disabled at (0): [<0000000000000000>] 0x0
CPU: 41 UID: 0 PID: 6292 Comm: qemu-system-loo Tainted: G W 6.17.0-rc3+ #31 PREEMPT(full)
Tainted: [W]=WARN
Stack : 0000000000000076 0000000000000000 9000000004c28264 9000100092ff4000
        9000100092ff7b80 9000100092ff7b88 0000000000000000 9000100092ff7cc8
        9000100092ff7cc0 9000100092ff7cc0 9000100092ff7a00 0000000000000001
        0000000000000001 9000100092ff7b88 947d2f9216a5e8b9 900010008773d880
        00000000ffff8b9f fffffffffffffffe 0000000000000ba1 fffffffffffffffe
        000000000000003e 900000000825a15b 000010007ad38000 9000100092ff7ec0
        0000000000000000 0000000000000000 9000000006f3ac60 9000000007252000
        0000000000000000 00007ff746ff2230 0000000000000053 9000200088a021b0
        0000555556c9d190 0000000000000000 9000000004c2827c 000055556cfb5f40
        00000000000000b0 0000000000000007 0000000000000007 0000000000071c1d
Call Trace:
[<9000000004c2827c>] show_stack+0x5c/0x180
[<9000000004c20fac>] dump_stack_lvl+0x94/0xe4
[<9000000004c99c7c>] __might_resched+0x26c/0x290
[<9000000004f68968>] __might_fault+0x20/0x88
[<ffff800002311de0>] kvm_eiointc_regs_access.isra.0+0x88/0x380 [kvm]
[<ffff8000022f8514>] kvm_device_ioctl+0x194/0x290 [kvm]
[<900000000506b0d8>] sys_ioctl+0x388/0x1010
[<90000000063ed210>] do_syscall+0xb0/0x2d8
[<9000000004c25ef8>] handle_syscall+0xb8/0x158

Fixes: 1ad7efa552fd5 ("LoongArch: KVM: Add EIOINTC user mode read and write functions")
Signed-off-by: Bibo Mao <maobibo@loongson.cn>
---
 arch/loongarch/kvm/intc/eiointc.c | 33 ++++++++++++++++++++-----------
 1 file changed, 21 insertions(+), 12 deletions(-)

----------------------------------------------------------------------

New:  TUN/TAP & vhost_net: netdev queue flow control to avoid ptr_ring tail drop
[PATCH net-next v4 0/4] TUN/TAP & vhost_net: netdev queue flow control to avoid ptr_ring tail drop
Author: Simon Schippers <simon.schippers@tu-dortmund.de>

This patch series deals with TUN/TAP and vhost_net which drop incoming 
SKBs whenever their internal ptr_ring buffer is full. Instead, with this 
patch series, the associated netdev queue is stopped before this happens. 
This allows the connected qdisc to function correctly as reported by [1] 
and improves application-layer performance, see benchmarks.

This patch series includes TUN, TAP, and vhost_net because they share 
logic. Adjusting only one of them would break the others. Therefore, the 
patch series is structured as follows:
1. New ptr_ring_spare helper to check if the ptr_ring has spare capacity
2. Netdev queue flow control for TUN: Logic for stopping the queue upon 
full ptr_ring and waking the queue if ptr_ring has spare capacity
3. Additions for TAP: Similar logic for waking the queue
4. Additions for vhost_net: Calling TUN/TAP methods for waking the queue

Benchmarks ([2] & [3]):
- TUN: TCP throughput over real-world 120ms RTT OpenVPN connection 
improved by 36% (117Mbit/s vs 185 Mbit/s)
- TAP: TCP throughput to local qemu VM stays the same (2.2Gbit/s), an 
improvement by factor 2 at emulated 120ms RTT (98Mbit/s vs 198Mbit/s)
- TAP+vhost_net: TCP throughput to local qemu VM approx. the same 
(23.4Gbit/s vs 23.9Gbit/s), same performance at emulated 120ms RTT 
(200Mbit/s)
- TUN/TAP/TAP+vhost_net: Reduction of ptr_ring size to ~10 packets 
possible without losing performance

Possible future work:
- Introduction of Byte Queue Limits as suggested by Stephen Hemminger
- Adaption of the netdev queue flow control for ipvtap & macvtap

[1] Link: 
https://unix.stackexchange.com/questions/762935/traffic-shaping-ineffective-on-tun-device
[2] Link: 
https://cni.etit.tu-dortmund.de/storages/cni-etit/r/Research/Publications/2025/Gebauer_2025_VTCFall/Gebauer_VTCFall2025_AuthorsVersion.pdf
[3] Link: https://github.com/tudo-cni/nodrop

Links to previous versions:
V3: 
https://lore.kernel.org/netdev/20250825211832.84901-1-simon.schippers@tu-dortmund.de/T/#u
V2: 
https://lore.kernel.org/netdev/20250811220430.14063-1-simon.schippers@tu-dortmund.de/T/#u
V1: 
https://lore.kernel.org/netdev/20250808153721.261334-1-simon.schippers@tu-dortmund.de/T/#u

Changelog:
V3 -> V4:
- Target net-next instead of net
- Changed to patch series instead of single patch
- Changed to new title from old title
"TUN/TAP: Improving throughput and latency by avoiding SKB drops"
- Wake netdev queue with new helpers wake_netdev_queue when there is any 
spare capacity in the ptr_ring instead of waiting for it to be empty
- Use tun_file instead of tun_struct in tun_ring_recv as a more consistent 
logic
- Use smp_wmb() and smp_rmb() barrier pair, which avoids any packet drops 
that happened rarely before
- Use safer logic for vhost_net using RCU read locks to access TUN/TAP data

V2 -> V3: Added support for TAP and TAP+vhost_net.

V1 -> V2: Removed NETDEV_TX_BUSY return case in tun_net_xmit and removed 
unnecessary netif_tx_wake_queue in tun_ring_recv.



Simon Schippers (4):
  ptr_ring_spare: Helper to check if spare capacity of size cnt is
    available
  netdev queue flow control for TUN
  netdev queue flow control for TAP
  netdev queue flow control for vhost_net

 drivers/net/tap.c        | 28 ++++++++++++++++
 drivers/net/tun.c        | 39 ++++++++++++++++++++--
 drivers/vhost/net.c      | 34 +++++++++++++++----
 include/linux/if_tap.h   |  2 ++
 include/linux/if_tun.h   |  3 ++
 include/linux/ptr_ring.h | 71 ++++++++++++++++++++++++++++++++++++++++
 6 files changed, 168 insertions(+), 9 deletions(-)

----------------------------------------------------------------------

New:  crypto: hisilicon - qm updates BAR configuration
[PATCH v9 1/2] crypto: hisilicon - qm updates BAR configuration
Author: Longfang Liu <liulongfang@huawei.com>

On new platforms greater than QM_HW_V3, the configuration region for the
live migration function of the accelerator device is no longer
placed in the VF, but is instead placed in the PF.

Therefore, the configuration region of the live migration function
needs to be opened when the QM driver is loaded. When the QM driver
is uninstalled, the driver needs to clear this configuration.

Signed-off-by: Longfang Liu <liulongfang@huawei.com>
Reviewed-by: Shameer Kolothum <shameerkolothum@gmail.com>
Acked-by: Herbert Xu <herbert@gondor.apana.org.au>
---
 drivers/crypto/hisilicon/qm.c | 27 +++++++++++++++++++++++++++
 include/linux/hisi_acc_qm.h   |  3 +++
 2 files changed, 30 insertions(+)

----------------------------------------------------------------------

New:  update live migration configuration region
[PATCH v9 0/2] update live migration configuration region
Author: Longfang Liu <liulongfang@huawei.com>

On the new hardware platform, the configuration register space
of the live migration function is set on the PF, while on the
old platform, this part is placed on the VF.

Change v8 -> v9
	Update the version name for driver matching

Change v7 -> v8
	Resolve hardware compatibility issues.

Change v6 -> v7
	Update the comment of the live migration configuration scheme.

Change v5 -> v6
	Update VF device properties

Change v4 -> v5
	Remove BAR length alignment

Change v3 -> v4
	Rebase on kernel 6.15

Change v2 -> v3
	Put the changes of Pre_Copy into another bugfix patchset.

Change v1 -> v2
	Delete the vf_qm_state read operation in Pre_Copy 

Longfang Liu (2):
  crypto: hisilicon - qm updates BAR configuration
  hisi_acc_vfio_pci: adapt to new migration configuration

 drivers/crypto/hisilicon/qm.c                 |  27 +++
 .../vfio/pci/hisilicon/hisi_acc_vfio_pci.c    | 205 ++++++++++++------
 .../vfio/pci/hisilicon/hisi_acc_vfio_pci.h    |  13 ++
 include/linux/hisi_acc_qm.h                   |   3 +
 4 files changed, 187 insertions(+), 61 deletions(-)

----------------------------------------------------------------------

