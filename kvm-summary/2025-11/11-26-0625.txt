From df7682d40 to b50ef847a
KVM mailing list update from df7682d40 to b50ef847a

Top 15 contributor Email domains (Based on Email Body)

      9 kernel.org
      8 nvidia.com
      5 intel.com
      4 linux.ibm.com
      3 nutanix.com
      2 tu-dortmund.de
      1 redhat.com
      1 gmail.com
      1 amazon.com

Top 15 contributors (Based on Email Body)

      7  Ankit Agrawal <ankita@nvidia.com>
      5  =?UTF-8?q?Micha=C5=82=20Winiarski?= <michal.winiarski@intel.com>
      5  "Mike Rapoport (Microsoft)" <rppt@kernel.org>
      4  Marc Zyngier <maz@kernel.org>
      3  Andrew Donnellan <ajd@linux.ibm.com>
      2  Simon Schippers <simon.schippers@tu-dortmund.de>
      2  Khushit Shah <khushit.shah@nutanix.com>
      1  Nikita Kalyazin <kalyazin@amazon.com>
      1  Markus Armbruster <armbru@redhat.com>
      1  Jon Kohler <jon@nutanix.com>
      1  Heiko Carstens <hca@linux.ibm.com>
      1  Chelsy Ratnawat <chelsyratnawat2001@gmail.com>
      1  Alex Williamson <alex.williamson@nvidia.com>

===== Patch list in this time period =====


===== Patch Commit Messages ====

New:  KVM: arm64: Don't use FIELD_PREP() in initialisers
[PATCH] KVM: arm64: Don't use FIELD_PREP() in initialisers
Author: Marc Zyngier <maz@kernel.org>

Nathan reports that compiling with CONFIG_PTDUMP_STAGE2_DEBUGFS
results in a compilation failure, with the compiler moaning about
"braced-group within expression allowed only inside a function"...

Replace FIELD_PREP() with its shifting primitive, which does the
trick here.

Reported-by: Nathan Chancellor <nathan@kernel.org>
Fixes: 81e9fe5c6f25d ("KVM: arm64: Teach ptdump about FEAT_XNX permissions")
Closes: https://lore.kernel.org/r/20251125173929.GA3256322@ax162
Signed-off-by: Marc Zyngier <maz@kernel.org>
---
 arch/arm64/kvm/ptdump.c | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: Add endian casting to kvm_swap_s1_desc()
[PATCH] KVM: arm64: Add endian casting to kvm_swap_s1_desc()
Author: Marc Zyngier <maz@kernel.org>

Keep sparse quiet by explicitly casting endianness conversion
when swapping S1 descriptors.

Reported-by: kernel test robot <lkp@intel.com>
Closes: https://lore.kernel.org/oe-kbuild-all/202511260246.JQDGsQKa-lkp@intel.com/
Fixes: c59ca4b5b0c3f ("KVM: arm64: Implement HW access flag management in stage-1 SW PTW")
Signed-off-by: Marc Zyngier <maz@kernel.org>
---
 arch/arm64/kvm/at.c | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

----------------------------------------------------------------------

New:  userfaultfd: move vma_can_userfault out of line
[PATCH v2 1/5] userfaultfd: move vma_can_userfault out of line
Author: Mike Rapoport <rppt@kernel.org>


vma_can_userfault() has grown pretty big and it's not called on
performance critical path.

Move it out of line.

No functional changes.

Reviewed-by: David Hildenbrand (Red Hat) <david@kernel.org>
Signed-off-by: Mike Rapoport (Microsoft) <rppt@kernel.org>
---
 include/linux/userfaultfd_k.h | 36 ++---------------------------------
 mm/userfaultfd.c              | 34 +++++++++++++++++++++++++++++++++
 2 files changed, 36 insertions(+), 34 deletions(-)

----------------------------------------------------------------------

New:  mm, kvm: add guest_memfd support for uffd minor faults
[PATCH v2 0/5] mm, kvm: add guest_memfd support for uffd minor faults
Author: Mike Rapoport <rppt@kernel.org>


Hi,

These patches allow guest_memfd to notify userspace about minor page
faults using userfaultfd and let userspace to resolve these page faults
using UFFDIO_CONTINUE.

To allow UFFDIO_CONTINUE outside of the core mm I added a get_shmem_folio()
callback to vm_ops that allows an address space backing a VMA to return a
folio that exists in it's page cache (patch 2)

In order for guest_memfd to notify userspace about page faults, there is a
new VM_FAULT_UFFD_MINOR that a ->fault() handler can return to inform the
page fault handler that it needs to call handle_userfault() to complete the
fault (patch 3).
 
Patch 4 plumbs these new goodies into guest_memfd.

This series is the minimal change I've been able to come up with to allow
integration of guest_memfd with uffd and while refactoring uffd and making
mfill_atomic() flow more linear would have been a nice improvement, it's
way out of the scope of enabling uffd with guest_memfd.

v2 changes:
* rename ->get_shared_folio() to ->get_folio()
* hardwire VM_FAULF_UFFD_MINOR to 0 when CONFIG_USERFAULTFD=n

v1: https://patch.msgid.link/20251123102707.559422-1-rppt@kernel.org
* Introduce VM_FAULF_UFFD_MINOR to avoid exporting handle_userfault()
* Simplify vma_can_mfill_atomic()
* Rename get_pagecache_folio() to get_shared_folio() and use inode
  instead of vma as its argument

rfc: https://patch.msgid.link/20251117114631.2029447-1-rppt@kernel.org

Mike Rapoport (Microsoft) (4):
  userfaultfd: move vma_can_userfault out of line
  userfaultfd, shmem: use a VMA callback to handle UFFDIO_CONTINUE
  mm: introduce VM_FAULT_UFFD_MINOR fault reason
  guest_memfd: add support for userfaultfd minor mode

Nikita Kalyazin (1):
  KVM: selftests: test userfaultfd minor for guest_memfd

 include/linux/mm.h                            |   9 ++
 include/linux/mm_types.h                      |  10 +-
 include/linux/userfaultfd_k.h                 |  36 +-----
 mm/memory.c                                   |   2 +
 mm/shmem.c                                    |  20 +++-
 mm/userfaultfd.c                              |  80 +++++++++++---
 .../testing/selftests/kvm/guest_memfd_test.c  | 103 ++++++++++++++++++
 virt/kvm/guest_memfd.c                        |  28 +++++
 8 files changed, 236 insertions(+), 52 deletions(-)

----------------------------------------------------------------------

New:  vfio: export function to map the VMA
[PATCH v6 1/6] vfio: export function to map the VMA
Author: ankita <ankita@nvidia.com>


Take out the implementation to map the VMA to the PTE/PMD/PUD
as a separate function.

Export the function to be used by nvgrace-gpu module.

cc: Shameer Kolothum <skolothumtho@nvidia.com>
cc: Alex Williamson <alex@shazbot.org>
cc: Jason Gunthorpe <jgg@ziepe.ca>
Reviewed-by: Shameer Kolothum <skolothumtho@nvidia.com>
Signed-off-by: Ankit Agrawal <ankita@nvidia.com>
---
 drivers/vfio/pci/vfio_pci_core.c | 50 ++++++++++++++++++++------------
 include/linux/vfio_pci_core.h    |  3 ++
 2 files changed, 34 insertions(+), 19 deletions(-)

----------------------------------------------------------------------

New:  vfio/nvgrace-gpu: Support huge PFNMAP and wait for GPU ready post reset
[PATCH v6 0/6] vfio/nvgrace-gpu: Support huge PFNMAP and wait for GPU ready post reset
Author: ankita <ankita@nvidia.com>


NVIDIA's Grace based system have large GPU device memory. The device
memory is mapped as VM_PFNMAP in the VMM VMA. The nvgrace-gpu
module could make use of the huge PFNMAP support added in mm [1].

To achieve this, nvgrace-gpu module is updated to implement huge_fault ops.
The implementation establishes mapping according to the order request.
Note that if the PFN or the VMA address is unaligned to the order, the
mapping fallbacks to the PTE level.

Secondly, it is expected that the mapping not be re-established until
the GPU is ready post reset. Presence of the mappings during that time
could potentially leads to harmless corrected RAS events to be logged if
the CPU attempts to do speculative reads on the GPU memory on the Grace
systems.

It can take several seconds for the GPU to be ready. So it is desirable
that the time overlaps as much of the VM startup as possible to reduce
impact on the VM bootup time. The GPU readiness state is thus checked
on the first fault/huge_fault request which amortizes the GPU readiness
time. The GPU readiness is checked through BAR0 registers as is done
at the device probe.

Patch 1 splits the code to map at the various levels.

Patch 2 implements support for huge pfnmap.

Patch 3 vfio_pci_core_mmap cleanup.

Patch 4 split the code to check the device readiness.

Patch 5 reset_done handler implementation

Patch 6 Ensures that the GPU is ready before re-establishing the mapping
after reset.

Applied over 6.18-rc6.

Link: https://lore.kernel.org/all/20240826204353.2228736-1-peterx@redhat.com/ [1]

Changelog:
v6:
- Updated the vfio_pci_vmf_insert_pfn function to add more common code.
  (Thanks Shameer Kolothum)
- Added missing userspace offset for pgoff calculation for huge pfnmap.
  (Thanks Shameer Kolothum)
- Removed alignment for GPU memory. (Thanks Jason Gunthorpe)
- Collected Reviewed-by. (Thanks Shameer Kolothum)
- Miscellaneous cleanup, log messages fixup
  (Thanks Alex Williamson, Jason Gunthorpe, Shameer Kolothum)
Link: https://lore.kernel.org/all/20251124115926.119027-1-ankita@nvidia.com/ [v5]
- Updated gpu_mem_mapped with reset_done flag for clearer semantics. (6/7)
  (Thanks Alex Williamson)
- Renamed vfio_pci_map_pfn to vfio_pci_vmf_insert_pfn. (2/7)
  (Thanks Alex Williamson)
- Updated to hold memory_lock across the vmf_insert_pfn and the
  read/write access of the device. (7/7) (Thanks Alex Williamson)
- Used scoped_guard to simplify critical region. (1/7, 7/7)
[v4]
- Implemented reset_done handler to set gpu_mem_mapped flag. Cleaned up
  FLR detection path (Thanks Alex Williamson)
- Moved the premap check of the device readiness to a new function.
  Added locking to avoid races. (Thanks Alex Williamson)
- vfio_pci_core_mmap cleanup.
- Added ioremap to BAR0 during open.
Link: https://lore.kernel.org/all/20251121141141.3175-1-ankita@nvidia.com/ [v3]
- Moved the code for BAR mapping to a separate function.
- Added BAR0 mapping during open. Ensures BAR0 is mapped when registers
  are checked. (Thanks Alex Williamson, Jason Gunthorpe for suggestion)
- Added check for GPU readiness on nvgrace_gpu_map_device_mem. (Thanks
  Alex Williamson for the suggestion.
Link: https://lore.kernel.org/all/20251118074422.58081-1-ankita@nvidia.com/ [v2]
- Fixed build kernel warning
- subject text changes
- Rebased to 6.18-rc6.
Link: https://lore.kernel.org/all/20251117124159.3560-1-ankita@nvidia.com/ [v1]

Signed-off-by: Ankit Agrawal <ankita@nvidia.com>

Ankit Agrawal (6):
  vfio: export function to map the VMA
  vfio/nvgrace-gpu: Add support for huge pfnmap
  vfio: use vfio_pci_core_setup_barmap to map bar in mmap
  vfio/nvgrace-gpu: split the code to wait for GPU ready
  vfio/nvgrace-gpu: Inform devmem unmapped after reset
  vfio/nvgrace-gpu: wait for the GPU mem to be ready

 drivers/vfio/pci/nvgrace-gpu/main.c | 196 ++++++++++++++++++++++------
 drivers/vfio/pci/vfio_pci_core.c    |  65 ++++-----
 include/linux/vfio_pci_core.h       |   3 +
 3 files changed, 192 insertions(+), 72 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: Convert ICH_HCR_EL2_TDIR cap to EARLY_LOCAL_CPU_FEATURE
[PATCH] KVM: arm64: Convert ICH_HCR_EL2_TDIR cap to EARLY_LOCAL_CPU_FEATURE
Author: Marc Zyngier <maz@kernel.org>

Suzuki notices that making the ICH_HCR_EL2_TDIR capability a system
one isn't a very good idea, should we end-up with CPUs that have
asymmetric TDIR support (somehow unlikely, but you never know what
level of stupidity vendors are up to). For this hypothetical setup,
making this an "EARLY_LOCAL_CPU_FEATURE" is a much better option.

This is actually consistent with what we already do with GICv5
legacy interface, so flip the capability over.

Reported-by: Suzuki K Poulose <suzuki.poulose@arm.com>
Signed-off-by: Marc Zyngier <maz@kernel.org>
Fixes: 2a28810cbb8b2 ("KVM: arm64: GICv3: Detect and work around the lack of ICV_DIR_EL1 trapping")
Link: https://lore.kerenl.org/r/5df713d4-8b79-4456-8fd1-707ca89a61b6@arm.com
---
 arch/arm64/kernel/cpufeature.c | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: Fix potential NULL dereference in amd_pmu_refresh()
[PATCH] KVM: x86: Fix potential NULL dereference in amd_pmu_refresh()
Author: Chelsy Ratnawat <chelsyratnawat2001@gmail.com>

kvm_find_cpuid_entry_index() can return NULL if the guest CPUID
entry is missing, but amd_pmu_refresh() was dereferencing the pointer
without checking. This could cause a kernel crash.

Add a NULL check and fallback to AMD64_NUM_COUNTERS_CORE if the
entry is missing.

Signed-off-by: Chelsy Ratnawat <chelsyratnawat2001@gmail.com>
---
 arch/x86/kvm/svm/pmu.c | 10 ++++++++--
 1 file changed, 8 insertions(+), 2 deletions(-)

----------------------------------------------------------------------

New:  tun/tap & vhost-net: netdev queue flow
[PATCH net-next v6 0/8] tun/tap & vhost-net: netdev queue flow
Author: Simon Schippers <simon.schippers@tu-dortmund.de>


----------------------------------------------------------------------

New:  kvm: Don't assume accel_ioctl_end() preserves @errno
[PATCH] kvm: Don't assume accel_ioctl_end() preserves @errno
Author: Markus Armbruster <armbru@redhat.com>

Retrieve the @errno set by ioctl() before we call accel_ioctl_end()
instead of afterwards, so it works whether accel_ioctl_end() preserves
@errno or not.

Signed-off-by: Markus Armbruster <armbru@redhat.com>
---
 accel/kvm/kvm-all.c | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

----------------------------------------------------------------------

New:  KVM: s390: Use generic VIRT_XFER_TO_GUEST_WORK entry
[PATCH 0/3] KVM: s390: Use generic VIRT_XFER_TO_GUEST_WORK entry
Author: Andrew Donnellan <ajd@linux.ibm.com>

This series enables VIRT_XFER_TO_GUEST_WORK on s390.

This requires:

  1) adding a signal_exits stats counter, which is used by
     kvm_handle_signal_exit()
  2) moving the point where interrupts are enabled and disabled in the
     guest entry path, so that interrupts aren't enabled until after the
     __TI_sie flag is set
  3) enabling VIRT_XFER_TO_GUEST_WORK and adding the appropriate calls to
     check for and handle outstanding work in __vcpu_run() and the VSIE
     path.

With this series applied, the kvm-unit-tests suite passes on both the host
and an L1 guest with nested KVM enabled, and benchmarks done using the
exittime tests from kvm-unit-tests show that the impact on entry path
performance is generally small enough to be noise (in my tests, around
+/-3%, running directly in an LPAR and in a L1 KVM guest).

Thanks to Heiko for feedback and guidance on this.

Signed-off-by: Andrew Donnellan <ajd@linux.ibm.com>
---
Andrew Donnellan (2):
      KVM: s390: Add signal_exits counter
      KVM: s390: Use generic VIRT_XFER_TO_GUEST_WORK functions

Heiko Carstens (1):
      KVM: s390: Enable and disable interrupts in entry code

 arch/s390/include/asm/kvm_host.h   |  1 +
 arch/s390/include/asm/stacktrace.h |  1 +
 arch/s390/kernel/asm-offsets.c     |  1 +
 arch/s390/kernel/entry.S           |  2 ++
 arch/s390/kvm/Kconfig              |  1 +
 arch/s390/kvm/kvm-s390.c           | 34 +++++++++++++++++++++-------------
 arch/s390/kvm/vsie.c               | 17 ++++++++++++-----
 7 files changed, 39 insertions(+), 18 deletions(-)

----------------------------------------------------------------------

New:  KVM: s390: Add signal_exits counter
[PATCH 1/3] KVM: s390: Add signal_exits counter
Author: Andrew Donnellan <ajd@linux.ibm.com>

Add a signal_exits counter for s390, as exists on arm64, loongarch, mips,
powerpc, riscv and x86.

This is used by kvm_handle_signal_exit(), which we will use when we
later enable CONFIG_VIRT_XFER_TO_GUEST_WORK.

Signed-off-by: Andrew Donnellan <ajd@linux.ibm.com>
---
 arch/s390/include/asm/kvm_host.h | 1 +
 arch/s390/kvm/kvm-s390.c         | 4 +++-
 2 files changed, 4 insertions(+), 1 deletion(-)

----------------------------------------------------------------------

New:  drm/xe/pf: Enable SR-IOV VF migration
[PATCH v6 1/4] drm/xe/pf: Enable SR-IOV VF migration
Author: Michał Winiarski <michal.winiarski@intel.com>

All of the necessary building blocks are now in place to support SR-IOV
VF migration.
Flip the enable/disable logic to match VF code and disable the feature
only for platforms that don't meet the necessary prerequisites.

Signed-off-by: Michał Winiarski <michal.winiarski@intel.com>
---
 drivers/gpu/drm/xe/xe_gt_sriov_pf_migration.c |  9 +++++
 drivers/gpu/drm/xe/xe_sriov_pf_migration.c    | 35 ++++++++++++++++---
 drivers/gpu/drm/xe/xe_sriov_pf_migration.h    |  1 +
 .../gpu/drm/xe/xe_sriov_pf_migration_types.h  |  4 +--
 4 files changed, 42 insertions(+), 7 deletions(-)

----------------------------------------------------------------------

New:  vfio/xe: Add driver variant for Xe VF migration
[PATCH v6 0/4] vfio/xe: Add driver variant for Xe VF migration
Author: Michał Winiarski <michal.winiarski@intel.com>

Hi,

We're now at v6, thanks for all the review feedback.

First 24 patches are now already merged through drm-tip tree, and I hope
we can get the remaining ones through the VFIO tree.
No major changes worth highlighting in this rev. Full changelog can be
found below.

Cover letter from the previous revision:

Xe is a DRM driver supporting Intel GPUs and for SR-IOV capable
devices, it enables the creation of SR-IOV VFs.
This series adds xe-vfio-pci driver variant that interacts with Xe
driver to control VF device state and read/write migration data,
allowing it to extend regular vfio-pci functionality with VFIO migration
capability.
The driver doesn't expose PRE_COPY support, as currently supported
hardware lacks the capability to track dirty pages.

While Xe driver already had the capability to manage VF device state,
management of migration data was something that needed to be implemented
and constitutes the majority of the series.

The migration data is processed asynchronously by the Xe driver, and is
organized into multiple migration data packet types representing the
hardware interfaces of the device (GGTT / MMIO / GuC FW / VRAM).
Since the VRAM can potentially be larger than available system memory,
it is copied in multiple chunks. The metadata needed for migration
compatibility decisions is added as part of descriptor packet (currently
limited to PCI device ID / revision).
Xe driver abstracts away the internals of packet processing and takes
care of tracking the position within individual packets.
The API exported to VFIO is similar to API exported by VFIO to
userspace, a simple .read()/.write().

Note that some of the VF resources are not virtualized (e.g. GGTT - the
GFX device global virtual address space). This means that the VF driver
needs to be aware that migration has occurred in order to properly
relocate (patching or reemiting data that contains references to GGTT
addresses) before resuming operation.
The code to handle that is already present in upstream Linux and in
production VF drivers for other OSes.

Links to previous revisions for reference.
v1:
https://lore.kernel.org/lkml/20251011193847.1836454-1-michal.winiarski@intel.com/
v2:
https://lore.kernel.org/lkml/20251021224133.577765-1-michal.winiarski@intel.com/
v3:
https://lore.kernel.org/lkml/20251030203135.337696-1-michal.winiarski@intel.com/
v4:
https://lore.kernel.org/lkml/20251105151027.540712-1-michal.winiarski@intel.com/
v5:
https://lore.kernel.org/lkml/20251111010439.347045-1-michal.winiarski@intel.com/

v5 -> v6:
* Exclude the patches already merged through drm-tip
* Add logging when migration is enabled in debug mode (Michał)
* Rename the xe_pf_get_pf helper (Michał)
* Don't use "vendor specific" (yet again) (Michał)
* Kerneldoc tweaks (Michał)
* Use guard(xe_pm_runtime_noresume) instead of assert (Michał)
* Check for num_vfs rather than total_vfs (Michał)

v4 -> v5:
* Require GuC version >= 70.54.0
* Fix VFIO migration migf disable
* Fix null-ptr-deref on save_read error
* Don't use "vendor specific" (again) (Kevin)
* Introduce xe_sriov_packet_types.h (Michał)
* Kernel-doc fixes (Michał)
* Use tile_id / gt_id instead of tile / gt in packet header (Michał)
* Don't use struct_group() in packet (Michał)
* And other, more minor changes

v3 -> v4:
* Add error handling on data_read / data_write path
* Don't match on PCI class, use PCI_DRIVER_OVERRIDE_DEVICE_VFIO helper
  instead (Lucas De Marchi)
* Use proper node VMA size inside GGTT save / restore helper (Michał)
* Improve data tracking set_bit / clear_bit wrapper names (Michał)
* Improve packet dump helper (Michał)
* Use drmm for migration mutex init (Michał)
* Rename the pf_device access helper (Michał)
* Use non-interruptible sleep in VRAM copy (Matt)
* Rename xe_sriov_migration_data to xe_sriov_packet along with relevant
  functions (Michał)
* Rename per-vf device-level data to xe_sriov_migration_state (Michał)
* Use struct name that matches component name instead of anonymous
  struct (Michał)
* Don't add XE_GT_SRIOV_STATE_MAX to state enum, use a helper macro
  instead (Michał)
* Kernel-doc fixes (Michał)

v2 -> v3:
* Bind xe-vfio-pci to specific devices instead of using vendor and
  class (Christoph Hellwig / Jason Gunthorpe)
* Don't refer to the driver as "vendor specific" (Christoph)
* Use pci_iov_get_pf_drvdata and change the interface to take xe_device
  (Jason)
* Update the RUNNING_P2P comment (Jason / Kevin Tian)
* Add state_mutex to protect device state transitions (Kevin)
* Implement .error_detected (Kevin)
* Drop redundant comments (Kevin)
* Explain 1-based indexing and wait_flr_done (Kevin)
* Add a missing get_file() (Kevin)
* Drop redundant state transitions when p2p is supported (Kevin)
* Update run/stop naming to match other drivers (Kevin)
* Fix error state handling (Kevin)
* Fix SAVE state diagram rendering (Michał Wajdeczko)
* Control state machine flipping PROCESS / WAIT logic (Michał Wajdeczko)
* Drop GUC / GGTT / MMIO / VRAM from SAVE control state machine
* Use devm instead of drmm for migration-related allocations (Michał)
* Use GGTT node for size calculations (Michał)
* Use mutex guards consistently (Michał)
* Fix build break on 32-bit (lkp)
* Kernel-doc updates (Michał)
* And other, more minor changes

v1 -> v2:
* Do not require debug flag to support migration on PTL/BMG
* Fix PCI class match on VFIO side
* Reorganized PF Control state machine (Michał Wajdeczko)
* Kerneldoc tidying (Michał Wajdeczko)
* Return NULL instead of -ENODATA for produce/consume (Michał Wajdeczko)
* guc_buf s/sync/sync_read (Matt Brost)
* Squash patch 03 (Matt Brost)
* Assert on PM ref instead of taking it (Matt Brost)
* Remove CCS completely (Matt Brost)
* Return ptr on guc_buf_sync_read (Michał Wajdeczko)
* Define default guc_buf size (Michał Wajdeczko)
* Drop CONFIG_PCI_IOV=n stubs where not needed (Michał Wajdeczko)
* And other, more minor changes

Michał Winiarski (4):
  drm/xe/pf: Enable SR-IOV VF migration
  drm/xe/pci: Introduce a helper to allow VF access to PF xe_device
  drm/xe/pf: Export helpers for VFIO
  vfio/xe: Add device specific vfio_pci driver variant for Intel
    graphics

 MAINTAINERS                                   |   7 +
 drivers/gpu/drm/xe/Makefile                   |   2 +
 drivers/gpu/drm/xe/xe_gt_sriov_pf_migration.c |   9 +
 drivers/gpu/drm/xe/xe_pci.c                   |  17 +
 drivers/gpu/drm/xe/xe_pci.h                   |   3 +
 drivers/gpu/drm/xe/xe_sriov_pf_migration.c    |  35 +-
 drivers/gpu/drm/xe/xe_sriov_pf_migration.h    |   1 +
 .../gpu/drm/xe/xe_sriov_pf_migration_types.h  |   4 +-
 drivers/gpu/drm/xe/xe_sriov_vfio.c            | 276 +++++++++
 drivers/vfio/pci/Kconfig                      |   2 +
 drivers/vfio/pci/Makefile                     |   2 +
 drivers/vfio/pci/xe/Kconfig                   |  12 +
 drivers/vfio/pci/xe/Makefile                  |   3 +
 drivers/vfio/pci/xe/main.c                    | 568 ++++++++++++++++++
 include/drm/intel/xe_sriov_vfio.h             |  30 +
 15 files changed, 964 insertions(+), 7 deletions(-)

----------------------------------------------------------------------

New:  vfio/pci: Use RCU for error/request triggers to avoid circular locking
[PATCH] vfio/pci: Use RCU for error/request triggers to avoid circular locking
Author: Alex Williamson <alex@shazbot.org>


Thanks to a device generating an ACS violation during bus reset,
lockdep reported the following circular locking issue:

CPU0: SET_IRQS (MSI/X): holds igate, acquires memory_lock
CPU1: HOT_RESET: holds memory_lock, acquires pci_bus_sem
CPU2: AER: holds pci_bus_sem, acquires igate

This results in a potential 3-way deadlock.

Remove the pci_bus_sem->igate leg of the triangle by using RCU
to peek at the eventfd rather than locking it with igate.

Fixes: 3be3a074cf5b ("vfio-pci: Don't use device_lock around AER interrupt setup")
Signed-off-by: Alex Williamson <alex.williamson@nvidia.com>
---
 drivers/vfio/pci/vfio_pci_core.c  | 68 ++++++++++++++++++++++---------
 drivers/vfio/pci/vfio_pci_intrs.c | 52 ++++++++++++++---------
 drivers/vfio/pci/vfio_pci_priv.h  |  4 ++
 include/linux/vfio_pci_core.h     | 10 ++++-
 4 files changed, 93 insertions(+), 41 deletions(-)

----------------------------------------------------------------------

