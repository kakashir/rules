From efafdabae to 7b38cd471
KVM mailing list update from efafdabae to 7b38cd471

Top 15 contributor Email domains (Based on Email Body)

     23 linux.intel.com
     21 google.com
     11 amd.com
      7 kernel.org
      4 rsg.ci.i.u-tokyo.ac.jp
      4 loongson.cn
      3 redhat.com
      1 tencent.com
      1 linux.ibm.com
      1 gmail.com

Top 15 contributors (Based on Email Body)

     16  Sean Christopherson <seanjc@google.com>
     15  Dapeng Mi <dapeng1.mi@linux.intel.com>
      9  John Allen <john.allen@amd.com>
      7  Marc Zyngier <maz@kernel.org>
      7  Kan Liang <kan.liang@linux.intel.com>
      4  Bibo Mao <maobibo@loongson.cn>
      4  Akihiko Odaki <odaki@rsg.ci.i.u-tokyo.ac.jp>
      3  James Houghton <jthoughton@google.com>
      3  Alex Williamson <alex.williamson@redhat.com>
      2  Sandipan Das <sandipan.das@amd.com>
      2  Mingwei Zhang <mizhang@google.com>
      1  Yuguo Li <cs.hugolee@gmail.com>
      1  Xiong Zhang <xiong.y.zhang@linux.intel.com>
      1  Henry Martin <bsdhenryma@tencent.com>
      1  Andrew Donnellan <ajd@linux.ibm.com>

===== Patch list in this time period =====


===== Patch Commit Messages ====

New:  KVM: Add fault injection for some MMU operations
[PATCH 1/2] KVM: Add fault injection for some MMU operations
Author: James Houghton <jthoughton@google.com>

Provide fault injection hooks for three operations:
1. For all architectures, retries due to invalidation notifiers.
2. For x86, TDP MMU cmpxchg updates for SPTEs.
3. For x86, TDP MMU SPTE iteration rescheduling.

For all of these, fault injection can induce the uncommon cases: (1)
that an invalidation occurred, (2) a cmpxchg failed, and (3) that the
MMU lock is contended.

All of the debugfs directories for each of these injection points will
show up under the KVM debugfs directory (usually /sys/kernel/debug/kvm)
with the following names:
1. fail_kvm_mmu_invalidate_retry
2. fail_tdp_mmu_cmpxchg
3. fail_tdp_mmu_resched

Signed-off-by: James Houghton <jthoughton@google.com>
---
 arch/x86/kvm/Makefile              |  1 +
 arch/x86/kvm/debugfs.c             |  6 +++++
 arch/x86/kvm/mmu/fault_injection.c | 36 ++++++++++++++++++++++++++++++
 arch/x86/kvm/mmu/fault_injection.h | 31 +++++++++++++++++++++++++
 arch/x86/kvm/mmu/mmu.c             |  1 +
 arch/x86/kvm/mmu/tdp_mmu.c         | 10 ++++++---
 include/linux/kvm_host.h           | 19 +++++++++++++---
 lib/Kconfig.debug                  |  8 +++++++
 virt/kvm/kvm_main.c                | 25 +++++++++++++++++++++
 9 files changed, 131 insertions(+), 6 deletions(-)

----------------------------------------------------------------------

New:  KVM: Fault injection
[PATCH 0/2] KVM: Fault injection
Author: James Houghton <jthoughton@google.com>

Hi Sean and Paolo,

I've prepared a patch that adds some fault injection points into KVM MMU
code to better catch bugs in the future. I put the documentation changes
in their own patch; I'm happy to squash them if you want.

The three points I've added here are:
1. Make KVM think that MMU invalidations happen more often.
2. Make KVM think that cmpxchg for TDP MMU is failing more often.
3. Make KVM think that the MMU lock is contended while iterating over
   TDP MMU SPTEs.

Unfortunately I haven't caught any bugs with this yet, but a while ago
we added something like this to consistently reproduce a bug in the
Direct MMU (the old, Google-internal implementation of TDP MMU).

I tried putting a WARN in when the TDP MMU cmpxchg fails to simulate a
bug when cmpxchg fails (this was the case for us with Direct MMU :)),
and running a few of the selftests, I get a few cmpxchg failures at the
beginning of the test, but even with several vCPUs, they only appear at
the beginning of the test. With fault injection, we can get them
constantly, exposing more code paths to cmpxchg failures.

It would be really great if this could be hooked into syzkaller for
better coverage; not sure what's needed for that.

Also if you have any ideas for what other fault injection points make
sense, I'd be happy to add them.

Please let me know what you think. Thanks!

This patch is based on the tip of Linus's tree.

James Houghton (2):
  KVM: Add fault injection for some MMU operations
  Documentation: fault-injection: Add entries for KVM fault injection
    points

 .../fault-injection/fault-injection.rst       | 12 +++++++
 arch/x86/kvm/Makefile                         |  1 +
 arch/x86/kvm/debugfs.c                        |  6 ++++
 arch/x86/kvm/mmu/fault_injection.c            | 36 +++++++++++++++++++
 arch/x86/kvm/mmu/fault_injection.h            | 31 ++++++++++++++++
 arch/x86/kvm/mmu/mmu.c                        |  1 +
 arch/x86/kvm/mmu/tdp_mmu.c                    | 10 ++++--
 include/linux/kvm_host.h                      | 19 ++++++++--
 lib/Kconfig.debug                             |  8 +++++
 virt/kvm/kvm_main.c                           | 25 +++++++++++++
 10 files changed, 143 insertions(+), 6 deletions(-)

----------------------------------------------------------------------

New:  x86/boot: Move boot_*msr helpers to asm/shared/msr.h
[PATCH 1/2] x86/boot: Move boot_*msr helpers to asm/shared/msr.h
Author: John Allen <john.allen@amd.com>

The boot_rdmsr and boot_wrmsr helpers used to reduce the need for inline
assembly in the boot kernel can also be useful in code shared by boot
and run-time kernel code. Move these helpers to asm/shared/msr.h and
rename to raw_rdmsr and raw_wrmsr to indicate that these may also be
used outside of the boot kernel.

Signed-off-by: John Allen <john.allen@amd.com>
---
 arch/x86/boot/compressed/sev.c    |  7 ++++---
 arch/x86/boot/compressed/sev.h    |  6 +++---
 arch/x86/boot/cpucheck.c          | 16 ++++++++--------
 arch/x86/boot/msr.h               | 26 --------------------------
 arch/x86/include/asm/shared/msr.h | 15 +++++++++++++++
 5 files changed, 30 insertions(+), 40 deletions(-)

----------------------------------------------------------------------

New:  Support for SEV-ES guest shadow stack
[PATCH 0/2] Support for SEV-ES guest shadow stack
Author: John Allen <john.allen@amd.com>

For shadow stack support in SVM when using SEV-ES, the guest kernel needs to
save XSS to the GHCB in order for the hypervisor to determine the XSAVES save
area size.

This series can be applied independently of the hypervisor series in order to
support non-KVM hypervisors.

John Allen (2):
  x86/boot: Move boot_*msr helpers to asm/shared/msr.h
  x86/sev-es: Include XSS value in GHCB CPUID request

 arch/x86/boot/compressed/sev.c    |  7 ++++---
 arch/x86/boot/compressed/sev.h    |  6 +++---
 arch/x86/boot/cpucheck.c          | 16 ++++++++--------
 arch/x86/boot/msr.h               | 26 --------------------------
 arch/x86/coco/sev/vc-shared.c     | 11 +++++++++++
 arch/x86/include/asm/shared/msr.h | 15 +++++++++++++++
 arch/x86/include/asm/svm.h        |  1 +
 7 files changed, 42 insertions(+), 40 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: SVM: Emulate reads and writes to shadow stack MSRs
[PATCH v3 1/5] KVM: x86: SVM: Emulate reads and writes to shadow stack MSRs
Author: John Allen <john.allen@amd.com>

Set up interception of shadow stack MSRs. In the event that shadow stack
is unsupported on the host or the MSRs are otherwise inaccessible, the
interception code will return an error. In certain circumstances such as
host initiated MSR reads or writes, the interception code will get or
set the requested MSR value.

Signed-off-by: John Allen <john.allen@amd.com>
---
 arch/x86/kvm/svm/svm.c | 18 ++++++++++++++++++
 1 file changed, 18 insertions(+)

----------------------------------------------------------------------

New:  Enable Shadow Stack Virtualization for SVM
[PATCH v3 0/5] Enable Shadow Stack Virtualization for SVM
Author: John Allen <john.allen@amd.com>

AMD Zen3 and newer processors support shadow stack, a feature designed
to protect against ROP (return-oriented programming) attacks in which an
attacker manipulates return addresses on the call stack in order to
execute arbitrary code. To prevent this, shadow stacks can be allocated
that are only used by control transfer and return instructions. When a
CALL instruction is issued, it writes the return address to both the
program stack and the shadow stack. When the subsequent RET instruction
is issued, it pops the return address from both stacks and compares
them. If the addresses don't match, a control-protection exception is
raised.

Shadow stack and a related feature, Indirect Branch Tracking (IBT), are
collectively referred to as Control-flow Enforcement Technology (CET).
However, current AMD processors only support shadow stack and not IBT.

This series adds support for shadow stack in SVM guests and builds upon
the support added in the CET guest support patch series [1]. Additional
patches are required to support shadow stack enabled guests in qemu [2].

[1]: CET guest support patches (v11)
https://lore.kernel.org/all/20250704085027.182163-1-chao.gao@intel.com/

[2]: CET qemu patches
https://lore.kernel.org/all/20230720111445.99509-1-weijiang.yang@intel.com/

[3]:  Previous SVM support patches (v2)
https://lore.kernel.org/all/20240226213244.18441-1-john.allen@amd.com/

---

RFC v2:
  - Rebased on v3 of the Intel CET virtualization series, dropping the
    patch that moved cet_is_msr_accessible to common code as that has
    been pulled into the Intel series.
  - Minor change removing curly brackets around if statement introduced
    in patch 6/6.
RFC v3:
  - Rebased on v5 of the Intel CET virtualization series.
  - Add patch changing the name of vmplX_ssp SEV-ES save area fields to
    plX_ssp.
  - Merge this series intended for KVM with the separate guest kernel
    patch (now patch 7/8).
  - Update MSR passthrough code to conditionally pass through shadow
    stack MSRS based on both host and guest support.
  - Don't save PL0_SSP, PL1_SSP, and PL2_SSP MSRs on SEV-ES VMRUN as
    these are currently unused.
v1:
  - Remove RFC tag from series
  - Rebase on v6 of the Intel CET virtualization series
  - Use KVM-governed feature to track SHSTK for SVM
v2:
  - Add new patch renaming boot_*msr to raw_*msr. Utilize raw_rdmsr when
    reading XSS on SEV-ES cpuid instructions.
  - Omit unnecessary patch for saving shadow stack msrs on SEV-ES VMRUN
  - Omit passing through of XSS for SEV-ES as support has already been
    properly implemented in a26b7cd22546 ("KVM: SEV: Do not intercept
    accesses to MSR_IA32_XSS for SEV-ES guests") 
v3:
  - Rebased on v11 of the Intel CET Virtualization series.
  - Split guest kernel patches into a separate series as these are
    independent of this series and are needed to support non-KVM
    hypervisors.

John Allen (5):
  KVM: x86: SVM: Emulate reads and writes to shadow stack MSRs
  KVM: x86: SVM: Update dump_vmcb with shadow stack save area additions
  KVM: x86: SVM: Pass through shadow stack MSRs
  KVM: SVM: Add MSR_IA32_XSS to the GHCB for hypervisor kernel
  KVM: SVM: Enable shadow stack virtualization for SVM

 arch/x86/kvm/svm/sev.c |  9 +++++++--
 arch/x86/kvm/svm/svm.c | 39 ++++++++++++++++++++++++++++++++++-----
 arch/x86/kvm/svm/svm.h |  1 +
 3 files changed, 42 insertions(+), 7 deletions(-)

----------------------------------------------------------------------

New:  perf: Skip pmu_ctx based on event_type
[PATCH v5 01/44] perf: Skip pmu_ctx based on event_type
Author: Sean Christopherson <seanjc@google.com>


To optimize the cgroup context switch, the perf_event_pmu_context
iteration skips the PMUs without cgroup events. A bool cgroup was
introduced to indicate the case. It can work, but this way is hard to
extend for other cases, e.g. skipping non-mediated PMUs. It doesn't
make sense to keep adding bool variables.

Pass the event_type instead of the specific bool variable. Check both
the event_type and related pmu_ctx variables to decide whether skipping
a PMU.

Event flags, e.g., EVENT_CGROUP, should be cleard in the ctx->is_active.
Add EVENT_FLAGS to indicate such event flags.

No functional change.

Signed-off-by: Kan Liang <kan.liang@linux.intel.com>
Tested-by: Yongwei Ma <yongwei.ma@intel.com>
Signed-off-by: Mingwei Zhang <mizhang@google.com>
Signed-off-by: Sean Christopherson <seanjc@google.com>
---
 kernel/events/core.c | 74 ++++++++++++++++++++++++--------------------
 1 file changed, 40 insertions(+), 34 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: Add support for mediated vPMUs
[PATCH v5 00/44] KVM: x86: Add support for mediated vPMUs
Author: Sean Christopherson <seanjc@google.com>

This series is based on the fastpath+PMU cleanups series[*] (which is based on
kvm/queue), but the non-KVM changes apply cleanly on v6.16 or Linus' tree.
I.e. if you only care about the perf changes, I would just apply on whatever
branch is convenient and stop when you hit the KVM changes.

My hope/plan is that the perf changes will go through the tip tree with a
stable tag/branch, and the KVM changes will go the kvm-x86 tree.

Non-x86 KVM folks, y'all are getting Cc'd due to minor changes in "KVM: Add a
simplified wrapper for registering perf callbacks".

The full set is also available at:

  https://github.com/sean-jc/linux.git tags/mediated-vpmu-v5

Add support for mediated vPMUs in KVM x86, where "mediated" aligns with the
standard definition of intercepting control operations (e.g. event selectors),
while allowing the guest to perform data operations (e.g. read PMCs, toggle
counters on/off) without KVM getting involed.

For an in-depth description of the what and why, please see the cover letter
from the original RFC:

  https://lore.kernel.org/all/20240126085444.324918-1-xiong.y.zhang@linux.intel.com

All KVM tests pass (or fail the same before and after), and I've manually
verified MSR/PMC are passed through as expected, but I haven't done much at all
to actually utilize the PMU in a guest.  I'll be amazed if I didn't make at
least one major goof.

Similarly, I tried to address all feedback, but there are many, many changes
relative to v4.  If I missed something, I apologize in advance.

In other words, please thoroughly review and test.

[*] https://lore.kernel.org/all/20250805190526.1453366-1-seanjc@google.com

v5:
 - Add a patch to call security_perf_event_free() from __free_event()
   instead of _free_event() (necessitated by the __cleanup() changes).
 - Add CONFIG_PERF_GUEST_MEDIATED_PMU to guard the new perf functionality.
 - Ensure the PMU is fully disabled in perf_{load,put}_guest_context() when
   when switching between guest and host context. [Kan, Namhyung]
 - Route the new system IRQ, PERF_GUEST_MEDIATED_PMI_VECTOR, through perf,
   not KVM, and play nice with FRED.
 - Rename and combine perf_{guest,host}_{enter,exit}() to a single set of
   APIs, perf_{load,put}_guest_context().
 - Rename perf_{get,put}_mediated_pmu() to perf_{create,release}_mediated_pmu()
   to (hopefully) better differentiate them from perf_{load,put}_guest_context().
 - Change the param to the load/put APIs from "u32 guest_lvtpc" to
   "unsigned long data" to decouple arch code as much as possible.  E.g. if
   a non-x86 arch were to ever support a mediated vPMU, @data could be used
   to pass a pointer to a struct.
 - Use pmu->version to detect if a vCPU has a mediated PMU.
 - Use a kvm_x86_ops hook to check for mediated PMU support.
 - Cull "passthrough" from as many places as I could find.
 - Improve the changelog/documentation related to RDPMC interception.
 - Check harware capabilities, not KVM capabilities, when calculating
   MSR and RDPMC intercepts.
 - Rework intercept (re)calculation to use a request and the existing (well,
   will be existing as of 6.17-rc1) vendor hooks for recalculating intercepts.
 - Always read PERF_GLOBAL_CTRL on VM-Exit if writes weren't intercepted while
   running the vCPU.
 - Call setup_vmcs_config() before kvm_x86_vendor_init() so that the golden
   VMCS configuration is known before kvm_init_pmu_capability() is called.
 - Keep as much refresh/init code in common x86 as possible.
 - Context switch PMCs and event selectors in common x86, not vendor code.
 - Bail from the VM-Exit fastpath if the guest is counting instructions
   retired and the mediated PMU is enabled (because guest state hasn't yet
   been synchronized with hardware).
 - Don't require an userspace to opt-in via KVM_CAP_PMU_CAPABILITY, and instead
   automatically "create" a mediated PMU on the first KVM_CREATE_VCPU call if
   the VM has an in-kernel local APIC.
 - Add entries in kernel-parameters.txt for the PMU params.
 - Add a patch to elide PMC writes when possible.
 - Many more fixups and tweaks...

v4:
 - https://lore.kernel.org/all/20250324173121.1275209-1-mizhang@google.com
 - Rebase whole patchset on 6.14-rc3 base.
 - Address Peter's comments on Perf part.
 - Address Sean's comments on KVM part.
   * Change key word "passthrough" to "mediated" in all patches
   * Change static enabling to user space dynamic enabling via KVM_CAP_PMU_CAPABILITY.
   * Only support GLOBAL_CTRL save/restore with VMCS exec_ctrl, drop the MSR
     save/retore list support for GLOBAL_CTRL, thus the support of mediated
     vPMU is constrained to SapphireRapids and later CPUs on Intel side.
   * Merge some small changes into a single patch.
 - Address Sandipan's comment on invalid pmu pointer.
 - Add back "eventsel_hw" and "fixed_ctr_ctrl_hw" to avoid to directly
   manipulate pmc->eventsel and pmu->fixed_ctr_ctrl.

v3: https://lore.kernel.org/all/20240801045907.4010984-1-mizhang@google.com
v2: https://lore.kernel.org/all/20240506053020.3911940-1-mizhang@google.com
v1: https://lore.kernel.org/all/20240126085444.324918-1-xiong.y.zhang@linux.intel.com

Dapeng Mi (15):
  KVM: x86/pmu: Start stubbing in mediated PMU support
  KVM: x86/pmu: Implement Intel mediated PMU requirements and
    constraints
  KVM: x86: Rename vmx_vmentry/vmexit_ctrl() helpers
  KVM: x86/pmu: Move PMU_CAP_{FW_WRITES,LBR_FMT} into msr-index.h header
  KVM: VMX: Add helpers to toggle/change a bit in VMCS execution
    controls
  KVM: x86/pmu: Disable RDPMC interception for compatible mediated vPMU
  KVM: x86/pmu: Load/save GLOBAL_CTRL via entry/exit fields for mediated
    PMU
  KVM: x86/pmu: Use BIT_ULL() instead of open coded equivalents
  KVM: x86/pmu: Disable interception of select PMU MSRs for mediated
    vPMUs
  KVM: x86/pmu: Bypass perf checks when emulating mediated PMU counter
    accesses
  KVM: x86/pmu: Reprogram mediated PMU event selectors on event filter
    updates
  KVM: x86/pmu: Load/put mediated PMU context when entering/exiting
    guest
  KVM: x86/pmu: Handle emulated instruction for mediated vPMU
  KVM: nVMX: Add macros to simplify nested MSR interception setting
  KVM: x86/pmu: Expose enable_mediated_pmu parameter to user space

Kan Liang (7):
  perf: Skip pmu_ctx based on event_type
  perf: Add generic exclude_guest support
  perf: Add APIs to create/release mediated guest vPMUs
  perf: Clean up perf ctx time
  perf: Add a EVENT_GUEST flag
  perf: Add APIs to load/put guest mediated PMU context
  perf/x86/intel: Support PERF_PMU_CAP_MEDIATED_VPMU

Mingwei Zhang (3):
  perf/x86/core: Plumb mediated PMU capability from x86_pmu to
    x86_pmu_cap
  KVM: x86/pmu: Introduce eventsel_hw to prepare for pmu event filtering
  KVM: nVMX: Disable PMU MSR interception as appropriate while running
    L2

Sandipan Das (3):
  perf/x86/core: Do not set bit width for unavailable counters
  perf/x86/amd: Support PERF_PMU_CAP_MEDIATED_VPMU for AMD host
  KVM: x86/pmu: Always stuff GuestOnly=1,HostOnly=0 for mediated PMCs on
    AMD

Sean Christopherson (15):
  perf: Move security_perf_event_free() call to __free_event()
  perf: core/x86: Register a new vector for handling mediated guest PMIs
  perf/x86: Switch LVTPC to/from mediated PMI vector on guest load/put
    context
  KVM: VMX: Setup canonical VMCS config prior to kvm_x86_vendor_init()
  KVM: SVM: Check pmu->version, not enable_pmu, when getting PMC MSRs
  KVM: Add a simplified wrapper for registering perf callbacks
  KVM: x86/pmu: Snapshot host (i.e. perf's) reported PMU capabilities
  KVM: x86/pmu: Implement AMD mediated PMU requirements
  KVM: x86: Rework KVM_REQ_MSR_FILTER_CHANGED into a generic
    RECALC_INTERCEPTS
  KVM: x86: Use KVM_REQ_RECALC_INTERCEPTS to react to CPUID updates
  KVM: x86/pmu: Move initialization of valid PMCs bitmask to common x86
  KVM: x86/pmu: Restrict GLOBAL_{CTRL,STATUS}, fixed PMCs, and PEBS to
    PMU v2+
  KVM: x86/pmu: Disallow emulation in the fastpath if mediated PMCs are
    active
  KVM: nSVM: Disable PMU MSR interception as appropriate while running
    L2
  KVM: x86/pmu: Elide WRMSRs when loading guest PMCs if values already
    match

Xiong Zhang (1):
  KVM: x86/pmu: Register PMI handler for mediated vPMU

 .../admin-guide/kernel-parameters.txt         |  49 ++
 arch/arm64/kvm/arm.c                          |   2 +-
 arch/loongarch/kvm/main.c                     |   2 +-
 arch/riscv/kvm/main.c                         |   2 +-
 arch/x86/entry/entry_fred.c                   |   1 +
 arch/x86/events/amd/core.c                    |   2 +
 arch/x86/events/core.c                        |  32 +-
 arch/x86/events/intel/core.c                  |   5 +
 arch/x86/include/asm/hardirq.h                |   3 +
 arch/x86/include/asm/idtentry.h               |   6 +
 arch/x86/include/asm/irq_vectors.h            |   4 +-
 arch/x86/include/asm/kvm-x86-ops.h            |   2 +-
 arch/x86/include/asm/kvm-x86-pmu-ops.h        |   4 +
 arch/x86/include/asm/kvm_host.h               |   7 +-
 arch/x86/include/asm/msr-index.h              |  17 +-
 arch/x86/include/asm/perf_event.h             |   1 +
 arch/x86/include/asm/vmx.h                    |   1 +
 arch/x86/kernel/idt.c                         |   3 +
 arch/x86/kernel/irq.c                         |  19 +
 arch/x86/kvm/Kconfig                          |   1 +
 arch/x86/kvm/cpuid.c                          |   2 +
 arch/x86/kvm/pmu.c                            | 272 ++++++++-
 arch/x86/kvm/pmu.h                            |  37 +-
 arch/x86/kvm/svm/nested.c                     |  18 +-
 arch/x86/kvm/svm/pmu.c                        |  51 +-
 arch/x86/kvm/svm/svm.c                        |  54 +-
 arch/x86/kvm/vmx/capabilities.h               |  11 +-
 arch/x86/kvm/vmx/main.c                       |  14 +-
 arch/x86/kvm/vmx/nested.c                     |  65 ++-
 arch/x86/kvm/vmx/pmu_intel.c                  | 169 ++++--
 arch/x86/kvm/vmx/pmu_intel.h                  |  15 +
 arch/x86/kvm/vmx/vmx.c                        | 143 +++--
 arch/x86/kvm/vmx/vmx.h                        |  11 +-
 arch/x86/kvm/vmx/x86_ops.h                    |   2 +-
 arch/x86/kvm/x86.c                            |  69 ++-
 arch/x86/kvm/x86.h                            |   1 +
 include/linux/kvm_host.h                      |  11 +-
 include/linux/perf_event.h                    |  38 +-
 init/Kconfig                                  |   4 +
 kernel/events/core.c                          | 521 ++++++++++++++----
 .../beauty/arch/x86/include/asm/irq_vectors.h |   3 +-
 virt/kvm/kvm_main.c                           |   6 +-
 42 files changed, 1385 insertions(+), 295 deletions(-)

----------------------------------------------------------------------

New:  vfio/fsl-mc: Mark for removal
[PATCH 1/2] vfio/fsl-mc: Mark for removal
Author: Alex Williamson <alex.williamson@redhat.com>

The driver has been orphaned for more than a year, mark it for removal.

Signed-off-by: Alex Williamson <alex.williamson@redhat.com>
---
 MAINTAINERS                       | 2 +-
 drivers/vfio/fsl-mc/Kconfig       | 5 ++++-
 drivers/vfio/fsl-mc/vfio_fsl_mc.c | 2 ++
 3 files changed, 7 insertions(+), 2 deletions(-)

----------------------------------------------------------------------

New:  vfio: Deprecate fsl-mc, platform, and amba
[PATCH 0/2] vfio: Deprecate fsl-mc, platform, and amba
Author: Alex Williamson <alex.williamson@redhat.com>

The vfio-fsl-mc driver has been orphaned since April 2024 after the
maintainer became unresponsive.  More than a year later, the driver
has only received community maintenance.  Let's take the next step
towards removal by marking it obsolete/deprecated.

The vfio-platform and vfio-amba drivers have an active maintainer,
but even the maintainer has no ability to test these drivers anymore.
The hardware itself has become obsolete and despite Eric's efforts to
add support for new devices and presenting on the complexities of
trying to manage and support shared resources at KVM Forum 2024, the
state of the driver and ability to test it upstream has not advanced.
The experiment has been useful, but seems to be reaching a conclusion.
QEMU intends to remove vfio-platform support in the 10.2 release.
Mark these drivers as obsolete/deprecated in the kernel as well.

Thanks,
Alex

Alex Williamson (2):
  vfio/fsl-mc: Mark for removal
  vfio/platform: Mark for removal

 MAINTAINERS                           |  4 ++--
 drivers/vfio/fsl-mc/Kconfig           |  5 ++++-
 drivers/vfio/fsl-mc/vfio_fsl_mc.c     |  2 ++
 drivers/vfio/platform/Kconfig         | 10 ++++++++--
 drivers/vfio/platform/reset/Kconfig   |  6 +++---
 drivers/vfio/platform/vfio_amba.c     |  2 ++
 drivers/vfio/platform/vfio_platform.c |  2 ++
 7 files changed, 23 insertions(+), 8 deletions(-)

----------------------------------------------------------------------

New:  arm64: Add capability denoting FEAT_RASv1p1
[PATCH v2 1/5] arm64: Add capability denoting FEAT_RASv1p1
Author: Marc Zyngier <maz@kernel.org>

Detecting FEAT_RASv1p1 is rather complicated, as there are two
ways for the architecture to advertise the same thing (always a
delight...).

Add a capability that will advertise this in a synthetic way to
the rest of the kernel.

Acked-by: Catalin Marinas <catalin.marinas@arm.com>
Signed-off-by: Marc Zyngier <maz@kernel.org>
---
 arch/arm64/kernel/cpufeature.c | 24 ++++++++++++++++++++++++
 arch/arm64/tools/cpucaps       |  1 +
 2 files changed, 25 insertions(+)

----------------------------------------------------------------------

New:  KVM: arm64: FEAT_RASv1p1 support and RAS selection
[PATCH v2 0/5] KVM: arm64: FEAT_RASv1p1 support and RAS selection
Author: Marc Zyngier <maz@kernel.org>

This is the next iteration of this series trying to plug some of our
RAS holes (no pun intended...). See [1] for the original series.

Patches on top of kvmarm-6.17.

* From v1 [1]:

  - Bunch of patches picked by Oliver (thanks!)

  - Added missing SYS_ERXMISC{2,3}_EL1 from the list of handled RAS
    registers

 - Added some rationale about the advertising of RASv1p1 (Cornelia)

  - Picked AB from Catalin (thanks!)

[1] https://lore.kernel.org/kvmarm/20250721101955.535159-1-maz@kernel.org

Marc Zyngier (5):
  arm64: Add capability denoting FEAT_RASv1p1
  KVM: arm64: Handle RASv1p1 registers
  KVM: arm64: Ignore HCR_EL2.FIEN set by L1 guest's EL2
  KVM: arm64: Expose FEAT_RASv1p1 in a canonical manner
  KVM: arm64: Make ID_AA64PFR0_EL1.RAS writable

 arch/arm64/kernel/cpufeature.c  | 24 ++++++++++++++++++++++++
 arch/arm64/kvm/hyp/vhe/switch.c |  5 ++++-
 arch/arm64/kvm/sys_regs.c       | 30 +++++++++++++++++++++++++++++-
 arch/arm64/tools/cpucaps        |  1 +
 4 files changed, 58 insertions(+), 2 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: PMU: Introduce
[PATCH RFC v2 1/2] KVM: arm64: PMU: Introduce
Author: Akihiko Odaki <odaki@rsg.ci.i.u-tokyo.ac.jp>

On heterogeneous arm64 systems, KVM's PMU emulation is based on the
features of a single host PMU instance. When a vCPU is migrated to a
pCPU with an incompatible PMU, counters such as PMCCNTR_EL0 stop
incrementing.

Although this behavior is permitted by the architecture, Windows does
not handle it gracefully and may crash with a division-by-zero error.

The current workaround requires VMMs to pin vCPUs to a set of pCPUs
that share a compatible PMU. This is difficult to implement correctly in
QEMU/libvirt, where pinning occurs after vCPU initialization, and it
also restricts the guest to a subset of available pCPUs.

This patch introduces the KVM_ARM_VCPU_PMU_V3_COMPOSITION attribute to
create a "composite" PMU. When set, KVM exposes a PMU that is compatible
with all pCPUs by advertising only a single cycle counter, a feature
common to all PMUs.

This allows Windows guests to run reliably on heterogeneous systems
without crashing, even without vCPU pinning, and enables VMMs to
schedule vCPUs across all available pCPUs, making full use of the host
hardware.

Signed-off-by: Akihiko Odaki <odaki@rsg.ci.i.u-tokyo.ac.jp>
---
 Documentation/virt/kvm/devices/vcpu.rst |  30 ++
 arch/arm64/include/asm/kvm_host.h       |   2 +
 arch/arm64/include/uapi/asm/kvm.h       |   1 +
 arch/arm64/kvm/arm.c                    |   5 +-
 arch/arm64/kvm/pmu-emul.c               | 495 +++++++++++++++++++-------------
 arch/arm64/kvm/sys_regs.c               |   2 +-
 include/kvm/arm_pmu.h                   |  12 +-
 7 files changed, 343 insertions(+), 204 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: PMU: Use multiple host PMUs
[PATCH RFC v2 0/2] KVM: arm64: PMU: Use multiple host PMUs
Author: Akihiko Odaki <odaki@rsg.ci.i.u-tokyo.ac.jp>

On heterogeneous arm64 systems, KVM's PMU emulation is based on the
features of a single host PMU instance. When a vCPU is migrated to a
pCPU with an incompatible PMU, counters such as PMCCNTR_EL0 stop
incrementing.

Although this behavior is permitted by the architecture, Windows does
not handle it gracefully and may crash with a division-by-zero error.

The current workaround requires VMMs to pin vCPUs to a set of pCPUs
that share a compatible PMU. This is difficult to implement correctly in
QEMU/libvirt, where pinning occurs after vCPU initialization, and it
also restricts the guest to a subset of available pCPUs.

This patch introduces the KVM_ARM_VCPU_PMU_V3_COMPOSITION attribute to
create a "composite" PMU. When set, KVM exposes a PMU that is compatible
with all pCPUs by advertising only a single cycle counter, a feature
common to all PMUs.

This allows Windows guests to run reliably on heterogeneous systems
without crashing, even without vCPU pinning, and enables VMMs to
schedule vCPUs across all available pCPUs, making full use of the host
hardware.

A QEMU patch that demonstrates the usage of the new attribute is
available at:
https://lore.kernel.org/qemu-devel/20250806-kvm-v1-1-d1d50b7058cd@rsg.ci.i.u-tokyo.ac.jp/
("[PATCH RFC] target/arm/kvm: Choose PMU backend")

Signed-off-by: Akihiko Odaki <odaki@rsg.ci.i.u-tokyo.ac.jp>
---
Changes in v2:
- Added the KVM_ARM_VCPU_PMU_V3_COMPOSITION attribute to opt in the
  feature.
- Added code to handle overflow.
- Link to v1: https://lore.kernel.org/r/20250319-hybrid-v1-1-4d1ada10e705@daynix.com

---
Akihiko Odaki (2):
      KVM: arm64: PMU: Introduce KVM_ARM_VCPU_PMU_V3_COMPOSITION
      KVM: arm64: selftests: Test guest PMUv3 composition

 Documentation/virt/kvm/devices/vcpu.rst            |  30 ++
 arch/arm64/include/asm/kvm_host.h                  |   2 +
 arch/arm64/include/uapi/asm/kvm.h                  |   1 +
 arch/arm64/kvm/arm.c                               |   5 +-
 arch/arm64/kvm/pmu-emul.c                          | 495 +++++++++++++--------
 arch/arm64/kvm/sys_regs.c                          |   2 +-
 include/kvm/arm_pmu.h                              |  12 +-
 .../selftests/kvm/arm64/vpmu_counter_access.c      | 148 ++++--
 8 files changed, 461 insertions(+), 234 deletions(-)

----------------------------------------------------------------------

New:  LoongArch: KVM: Small enhancements about IPI and
[PATCH v2 0/3] LoongArch: KVM: Small enhancements about IPI and
Author: Bibo Mao <maobibo@loongson.cn>

Thre are some small enhancement about IPI emulation and LBT enabling in
LoongArch KVM. With IPI, it supports sending command to vCPU itself. And
with LBT it adds flag checking int function kvm_own_lbt() and make it
robust.

Bibo Mao (3):
  LoongArch: KVM: Access mailbox directly in mail_send()
  LoongArch: KVM: Add implementation with IOCSR_IPI_SET
  LoongArch: KVM: Make function kvm_own_lbt() robust

 arch/loongarch/kvm/intc/ipi.c | 51 ++++++++++++++++++++++-------------
 arch/loongarch/kvm/vcpu.c     |  8 +++---
 2 files changed, 38 insertions(+), 21 deletions(-)

----------------------------------------------------------------------

New:  LoongArch: KVM: Access mailbox directly in mail_send()
[PATCH v2 1/3] LoongArch: KVM: Access mailbox directly in mail_send()
Author: Bibo Mao <maobibo@loongson.cn>

With function mail_send(), it is to write mailbox of other VCPUs.
Existing simple APIs read_mailbox/write_mailbox can be used directly
rather than send command on IOCSR address.

Signed-off-by: Bibo Mao <maobibo@loongson.cn>
---
 arch/loongarch/kvm/intc/ipi.c | 16 +++++++++++++---
 1 file changed, 13 insertions(+), 3 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: Synchronize APIC State with QEMU when irqchip=split
[PATCH] KVM: x86: Synchronize APIC State with QEMU when irqchip=split
Author: Yuguo Li <cs.hugolee@gmail.com>

When using split irqchip mode, IOAPIC is handled by QEMU while the LAPIC is emulated by KVM.
When guest disables LINT0, KVM doesn't exit to QEMU for synchronization, leaving IOAPIC unaware of this change.
This may cause vCPU to be kicked when external devices(e.g. PIT)keep sending interrupts.
This patch ensure that KVM exits to QEMU for synchronization when the guest disables LINT0.

Signed-off-by: Yuguo Li <hugoolli@tencent.com>
---
 arch/x86/include/asm/kvm_host.h | 1 +
 arch/x86/kvm/lapic.c            | 4 ++++
 arch/x86/kvm/x86.c              | 5 +++++
 include/uapi/linux/kvm.h        | 1 +
 4 files changed, 11 insertions(+)

----------------------------------------------------------------------

New:  KVM: PPC: Fix misleading interrupts comment in kvmppc_prepare_to_enter()
[PATCH] KVM: PPC: Fix misleading interrupts comment in kvmppc_prepare_to_enter()
Author: Andrew Donnellan <ajd@linux.ibm.com>

Until commit 6c85f52b10fd ("kvm/ppc: IRQ disabling cleanup"),
kvmppc_prepare_to_enter() was called with interrupts already disabled by
the caller, which was documented in the comment above the function.

Post-cleanup, the function is now called with interrupts enabled, and
disables interrupts itself.

Fix the comment to reflect the current behaviour.

Fixes: 6c85f52b10fd ("kvm/ppc: IRQ disabling cleanup")
Signed-off-by: Andrew Donnellan <ajd@linux.ibm.com>
---
 arch/powerpc/kvm/powerpc.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

----------------------------------------------------------------------

