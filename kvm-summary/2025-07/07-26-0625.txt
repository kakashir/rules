From 5ff7953eb to 0549e8a58
KVM mailing list update from 5ff7953eb to 0549e8a58

Top 15 contributor Email domains (Based on Email Body)

      6 redhat.com
      4 arm.com
      3 kernel.org
      3 google.com
      1 fb.com

Top 15 contributors (Based on Email Body)

      6  Igor Mammedov <imammedo@redhat.com>
      4  Andre Przywara <andre.przywara@arm.com>
      3  Raghavendra Rao Ananta <rananta@google.com>
      3  Marc Zyngier <maz@kernel.org>
      1  Alex Mastro <amastro@fb.com>

===== Patch list in this time period =====


===== Patch Commit Messages ====

New:  Sync kernel UAPI headers with v6.16-rc1
[PATCH kvmtool v2 1/6] Sync kernel UAPI headers with v6.16-rc1
Author: Andre Przywara <andre.przywara@arm.com>

Needed for ARM nested virt support.
Generated using util/update_headers.sh.

Signed-off-by: Andre Przywara <andre.przywara@arm.com>
---
 arm64/include/asm/kvm.h    | 23 ++++++++++--
 include/linux/kvm.h        |  5 +++
 include/linux/virtio_net.h | 13 +++++++
 include/linux/virtio_pci.h |  1 +
 riscv/include/asm/kvm.h    |  2 +
 x86/include/asm/kvm.h      | 75 ++++++++++++++++++++++++++++++++++++++
 6 files changed, 115 insertions(+), 4 deletions(-)

----------------------------------------------------------------------

New:  arm64: Nested virtualization support
[PATCH kvmtool v2 0/6] arm64: Nested virtualization support
Author: Andre Przywara <andre.przywara@arm.com>

v2 of the nested virt support series, just adding three patches from
Marc's repo, to complete the nested virt experience.
Marc, I added some commit messages to your patches, please have a look if
they make vaguely sense. Thanks!
========================================================

Thanks to the imperturbable efforts from Marc, arm64 support for nested
virtualization has now reached the mainline kernel, which means the
respective kvmtool support should now be ready as well.

Patch 1 updates the kernel headers, to get the new EL2 capability, and
the VGIC device control to setup the maintenance IRQ.
Patch 2 introduces the new "--nested" command line option, to let the
VCPUs start in EL2. To allow KVM guests running in such a guest, we also
need VGIC support, which patch 3 allows by setting the maintenance IRQ.
Patch 4 to 6 are picked from Marc's repo, and allow to set the arch
timer offset, enable non-VHE guests (at the cost of losing recursive
nested virtualisation), and also advertise the virtual EL2 timer IRQ.

Tested on the FVP (with some good deal of patience), and some commercial
(non-fruity) hardware, down to a guest's guest's guest.

Cheers,
Andre

Andre Przywara (3):
  Sync kernel UAPI headers with v6.16-rc1
  arm64: Initial nested virt support
  arm64: nested: add support for setting maintenance IRQ

Marc Zyngier (3):
  arm64: Add counter offset control
  arm64: add FEAT_E2H0 support (TBC)
  arm64: Generate HYP timer interrupt specifiers

 arm64/arm-cpu.c                     |  7 ++-
 arm64/fdt.c                         |  5 +-
 arm64/gic.c                         | 21 +++++++-
 arm64/include/asm/kvm.h             | 23 +++++++--
 arm64/include/kvm/gic.h             |  2 +-
 arm64/include/kvm/kvm-config-arch.h | 11 ++++-
 arm64/include/kvm/timer.h           |  2 +-
 arm64/kvm-cpu.c                     | 14 +++++-
 arm64/kvm.c                         | 17 +++++++
 arm64/timer.c                       | 29 +++++------
 include/linux/kvm.h                 |  5 ++
 include/linux/virtio_net.h          | 13 +++++
 include/linux/virtio_pci.h          |  1 +
 riscv/include/asm/kvm.h             |  2 +
 x86/include/asm/kvm.h               | 75 +++++++++++++++++++++++++++++
 15 files changed, 196 insertions(+), 31 deletions(-)

----------------------------------------------------------------------

New:  elements to u32
[kvm-unit-tests PATCH v4 1/5] x86: resize id_map[] elements to u32
Author: Igor Mammedov <imammedo@redhat.com>

currently item size is u8, which would truncate APIC IDs that are
greater than 255.
Make it u32 so that it  cna hold x2apic IDs as well.

Signed-off-by: Igor Mammedov <imammedo@redhat.com>
---
 lib/x86/apic.h | 2 +-
 lib/x86/apic.c | 2 +-
 2 files changed, 2 insertions(+), 2 deletions(-)

----------------------------------------------------------------------

New:  x86: add HPET counter tests
[kvm-unit-tests PATCH v4 0/5] x86: add HPET counter tests
Author: Igor Mammedov <imammedo@redhat.com>

Changelog:
  v4:
     * fix smap/pku/pks tests that were failing CI
     * on_cpus() wasn't running task on CPUs above 255,
       fix x86/smp code to correctly account for APIC IDs
       above 255
     * bump max cpus limit to 1024 
     * hpet: count 0 latency as failure to avoid missing
       APs that doesn't run reader task
     * hpet: replace on_cpus() with on_cpus_async() to
       to run reader task only on explicitly selected APs.
  v3:
     * fix test running long time due to control thread
       also running read test and stalling starting other threads 
     * improve latency accuracy 
     * increase max number of vcpus to 448
       (that's what I had in hands for testing)

previous rev:
   "[kvm-unit-tests PATCH v3 0/2] x86: add HPET counter tests"
   https://yhbt.net/lore/all/20250718155738.1540072-1-imammedo@redhat.com/T/#t

Igor Mammedov (5):
  x86: resize id_map[] elements to u32
  x86: fix APs with APIC ID more that 255 not showing in id_map
  x86: move USERBASE to 32Mb in smap/pku/pks tests
  x86: bump number of max cpus to 1024
  x86: add HPET counter read micro benchmark and enable/disable torture
    tests

 lib/x86/apic.h       |  2 +-
 lib/x86/smp.h        |  2 +-
 lib/x86/apic.c       |  2 +-
 lib/x86/setup.c      |  2 +-
 x86/Makefile.common  |  2 +
 x86/cstart.S         |  2 +-
 x86/hpet_read_test.c | 93 ++++++++++++++++++++++++++++++++++++++++++++
 x86/pks.c            |  2 +-
 x86/pku.c            |  2 +-
 x86/smap.c           |  2 +-
 10 files changed, 103 insertions(+), 8 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: Split kvm_pgtable_stage2_destroy()
[PATCH 1/2] KVM: arm64: Split kvm_pgtable_stage2_destroy()
Author: Raghavendra Rao Ananta <rananta@google.com>

Split kvm_pgtable_stage2_destroy() into two:
  - kvm_pgtable_stage2_destroy_range(), that performs the
    page-table walk and free the entries over a range of addresses.
  - kvm_pgtable_stage2_destroy_pgd(), that frees the PGD.

This refactoring enables subsequent patches to free large page-tables
in chunks, calling cond_resched() between each chunk, to yield the CPU
as necessary.

Direct callers of kvm_pgtable_stage2_destroy() will continue to walk
the entire range of the VM as before, ensuring no functional changes.

Also, add equivalent pkvm_pgtable_stage2_*() stubs to maintain 1:1
mapping of the page-table functions.

Signed-off-by: Raghavendra Rao Ananta <rananta@google.com>
---
 arch/arm64/include/asm/kvm_pgtable.h | 19 +++++++++++++++++++
 arch/arm64/include/asm/kvm_pkvm.h    |  3 +++
 arch/arm64/kvm/hyp/pgtable.c         | 23 ++++++++++++++++++++---
 arch/arm64/kvm/pkvm.c                | 11 +++++++++++
 4 files changed, 53 insertions(+), 3 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: Destroy the stage-2 page-table periodically
[PATCH 0/2] KVM: arm64: Destroy the stage-2 page-table periodically
Author: Raghavendra Rao Ananta <rananta@google.com>

Hello,

When destroying a fully-mapped 128G VM abruptly, the following scheduler
warning is observed:

  sched: CPU 0 need_resched set for > 100018840 ns (100 ticks) without schedule
  CPU: 0 UID: 0 PID: 9617 Comm: kvm_page_table_ Tainted: G O 6.16.0-smp-DEV #3 NONE
  Tainted: [O]=OOT_MODULE
  Call trace:
      show_stack+0x20/0x38 (C)
      dump_stack_lvl+0x3c/0xb8
      dump_stack+0x18/0x30
      resched_latency_warn+0x7c/0x88
      sched_tick+0x1c4/0x268
      update_process_times+0xa8/0xd8
      tick_nohz_handler+0xc8/0x168
      __hrtimer_run_queues+0x11c/0x338
      hrtimer_interrupt+0x104/0x308
      arch_timer_handler_phys+0x40/0x58
      handle_percpu_devid_irq+0x8c/0x1b0
      generic_handle_domain_irq+0x48/0x78
      gic_handle_irq+0x1b8/0x408
      call_on_irq_stack+0x24/0x30
      do_interrupt_handler+0x54/0x78
      el1_interrupt+0x44/0x88
      el1h_64_irq_handler+0x18/0x28
      el1h_64_irq+0x84/0x88
      stage2_free_walker+0x30/0xa0 (P)
      __kvm_pgtable_walk+0x11c/0x258
      __kvm_pgtable_walk+0x180/0x258
      __kvm_pgtable_walk+0x180/0x258
      __kvm_pgtable_walk+0x180/0x258
      kvm_pgtable_walk+0xc4/0x140
      kvm_pgtable_stage2_destroy+0x5c/0xf0
      kvm_free_stage2_pgd+0x6c/0xe8
      kvm_uninit_stage2_mmu+0x24/0x48
      kvm_arch_flush_shadow_all+0x80/0xa0
      kvm_mmu_notifier_release+0x38/0x78
      __mmu_notifier_release+0x15c/0x250
      exit_mmap+0x68/0x400
      __mmput+0x38/0x1c8
      mmput+0x30/0x68
      exit_mm+0xd4/0x198
      do_exit+0x1a4/0xb00
      do_group_exit+0x8c/0x120
      get_signal+0x6d4/0x778
      do_signal+0x90/0x718
      do_notify_resume+0x70/0x170
      el0_svc+0x74/0xd8
      el0t_64_sync_handler+0x60/0xc8
      el0t_64_sync+0x1b0/0x1b8

The host kernel was running with CONFIG_PREEMPT_NONE=y, and since the
page-table walk operation takes considerable amount of time for a VM
with such a large number of PTEs mapped, the warning is seen.

To mitigate this, split the walk into smaller ranges, by checking for
cond_resched() between each range. Since the path is executed during
VM destruction, after the page-table structure is unlinked from the
KVM MMU, relying on cond_resched_rwlock_write() isn't necessary.

Patch-1 splits the kvm_pgtable_stage2_destroy() function into separate
'walk' and 'free PGD' parts.

Patch-2 leverages the split and performs the walk periodically over
smaller ranges and calls cond_resched() between them.

Thank you.
Raghavendra

Raghavendra Rao Ananta (2):
  KVM: arm64: Split kvm_pgtable_stage2_destroy()
  KVM: arm64: Destroy the stage-2 page-table periodically

 arch/arm64/include/asm/kvm_pgtable.h | 19 ++++++++++++
 arch/arm64/kvm/hyp/pgtable.c         | 23 ++++++++++++--
 arch/arm64/kvm/mmu.c                 | 46 +++++++++++++++++++++++++---
 3 files changed, 80 insertions(+), 8 deletions(-)

----------------------------------------------------------------------

