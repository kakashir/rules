From 61c085bf3 to a8d17db02
KVM mailing list update from 61c085bf3 to a8d17db02

Top 15 contributor Email domains (Based on Email Body)

     22 kernel.org
     14 arm.com
     12 linux.dev
      2 linux.intel.com
      2 intel.com
      1 oss.qualcomm.com
      1 google.com
      1 gmail.com
      1 163.com

Top 15 contributors (Based on Email Body)

     17  "David Hildenbrand (Arm)" <david@kernel.org>
     12  Oliver Upton <oliver.upton@linux.dev>
      8  Yeoreum Yun <yeoreum.yun@arm.com>
      6  Suzuki K Poulose <suzuki.poulose@arm.com>
      4  Yosry Ahmed <yosry@kernel.org>
      2  Zide Chen <zide.chen@intel.com>
      2  Dapeng Mi <dapeng1.mi@linux.intel.com>
      1  =?UTF-8?q?Radim=20Kr=C4=8Dm=C3=A1=C5=99?= <radim.krcmar@oss.qualcomm.com>
      1  Jinyu Tang <tjytimi@163.com>
      1  Jim Mattson <jmattson@google.com>
      1  hbuxiaofei <hbuxiaofei@gmail.com>
      1  Bjorn Helgaas <helgaas@kernel.org>

===== Patch list in this time period =====


===== Patch Commit Messages ====

New:  mm/madvise: drop range checks in madvise_free_single_vma()
[PATCH v1 01/16] mm/madvise: drop range checks in madvise_free_single_vma()
Author: David Hildenbrand (Arm) <david@kernel.org>

madvise_vma_behavior()-> madvise_dontneed_free()->madvise_free_single_vma()
is only called from madvise_walk_vmas()

(a) After try_vma_read_lock() confirmed that the whole range falls into
    a single VMA (see is_vma_lock_sufficient()).

(b) After adjusting the range to the VMA in the loop afterwards.

madvise_dontneed_free() might drop the MM lock when handling
userfaultfd, but it properly looks up the VMA again to adjust the range.

So in madvise_free_single_vma(), the given range should always fall into
a single VMA and should also span at least one page.

Let's drop the error checks.

The code now matches what we do in madvise_dontneed_single_vma(), where
we call zap_vma_range_batched() that documents: "The range must fit into
one VMA.". Although that function still adjusts that range, we'll change
that soon.

Signed-off-by: David Hildenbrand (Arm) <david@kernel.org>
---
 mm/madvise.c | 13 ++++---------
 1 file changed, 4 insertions(+), 9 deletions(-)

----------------------------------------------------------------------

New:  mm: cleanups around unmapping / zapping
[PATCH v1 00/16] mm: cleanups around unmapping / zapping
Author: David Hildenbrand (Arm) <david@kernel.org>

A bunch of cleanups around unmapping and zapping. Mostly simplifications,
code movements, documentation and renaming of zapping functions.

With this series, we'll have the following high-level zap/unmap functions
(excluding high-level folio zapping):
* unmap_vmas() for actual unmapping (vmas will go away)
* zap_vma(): zap all page table entries in a vma
* zap_vma_for_reaping(): zap_vma() that must not block
* zap_vma_range(): zap a range of page table entries
* zap_vma_range_batched(): zap_vma_range() with more options and batching
* zap_special_vma_range(): limited zap_vma_range() for modules
* __zap_vma_range(): internal helper

Patch #1 is not about unmapping/zapping, but I stumbled over it while
verifying MADV_DONTNEED range handling.

Patch #16 is related to [1], but makes sense even independent of that.

[1] https://lore.kernel.org/r/aYSKyr7StGpGKNqW@google.com

The CC list is already long enough. As these are simple changes to
drivers/arch code, I'm only CCing maintainers of all changes but only
reviewers of the MM bits.

Cc: Andrew Morton <akpm@linux-foundation.org>
Cc: Lorenzo Stoakes <lorenzo.stoakes@oracle.com>
Cc: "Liam R. Howlett" <Liam.Howlett@oracle.com>
Cc: Vlastimil Babka <vbabka@kernel.org>
Cc: Mike Rapoport <rppt@kernel.org>
Cc: Suren Baghdasaryan <surenb@google.com>
Cc: Michal Hocko <mhocko@suse.com>
Cc: Jann Horn <jannh@google.com>
Cc: Pedro Falcato <pfalcato@suse.de>
Cc: David Rientjes <rientjes@google.com>
Cc: Shakeel Butt <shakeel.butt@linux.dev>
Cc: "Matthew Wilcox (Oracle)" <willy@infradead.org>
Cc: Alice Ryhl <aliceryhl@google.com>
Cc: Madhavan Srinivasan <maddy@linux.ibm.com>
Cc: Michael Ellerman <mpe@ellerman.id.au>
Cc: Christian Borntraeger <borntraeger@linux.ibm.com>
Cc: Janosch Frank <frankja@linux.ibm.com>
Cc: Claudio Imbrenda <imbrenda@linux.ibm.com>
Cc: Alexander Gordeev <agordeev@linux.ibm.com>
Cc: Gerald Schaefer <gerald.schaefer@linux.ibm.com>
Cc: Heiko Carstens <hca@linux.ibm.com>
Cc: Vasily Gorbik <gor@linux.ibm.com>
Cc: Jarkko Sakkinen <jarkko@kernel.org>
Cc: Thomas Gleixner <tglx@kernel.org>
Cc: Ingo Molnar <mingo@redhat.com>
Cc: Borislav Petkov <bp@alien8.de>
Cc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
Cc: "Arve Hjønnevåg" <arve@android.com>
Cc: Todd Kjos <tkjos@android.com>
Cc: Christian Brauner <brauner@kernel.org>
Cc: Carlos Llamas <cmllamas@google.com>
Cc: Alice Ryhl <aliceryhl@google.com>
Cc: Ian Abbott <abbotti@mev.co.uk>
Cc: H Hartley Sweeten <hsweeten@visionengravers.com>
Cc: Jani Nikula <jani.nikula@linux.intel.com>
Cc: Joonas Lahtinen <joonas.lahtinen@linux.intel.com>
Cc: Rodrigo Vivi <rodrigo.vivi@intel.com>
Cc: Tvrtko Ursulin <tursulin@ursulin.net>
Cc: David Airlie <airlied@gmail.com>
Cc: Simona Vetter <simona@ffwll.ch>
Cc: Jason Gunthorpe <jgg@ziepe.ca>
Cc: Leon Romanovsky <leon@kernel.org>
Cc: Dimitri Sivanich <dimitri.sivanich@hpe.com>
Cc: Arnd Bergmann <arnd@arndb.de>
Cc: Alexei Starovoitov <ast@kernel.org>
Cc: Daniel Borkmann <daniel@iogearbox.net>
Cc: Andrii Nakryiko <andrii@kernel.org>
Cc: Peter Zijlstra <peterz@infradead.org>
Cc: Arnaldo Carvalho de Melo <acme@kernel.org>
Cc: Namhyung Kim <namhyung@kernel.org>
Cc: Andy Lutomirski <luto@kernel.org>
Cc: Vincenzo Frascino <vincenzo.frascino@arm.com>
Cc: Eric Dumazet <edumazet@google.com>
Cc: Neal Cardwell <ncardwell@google.com>
Cc: "David S. Miller" <davem@davemloft.net>
Cc: David Ahern <dsahern@kernel.org>
Cc: Jakub Kicinski <kuba@kernel.org>
Cc: Paolo Abeni <pabeni@redhat.com>
Cc: Miguel Ojeda <ojeda@kernel.org>

Cc: linuxppc-dev@lists.ozlabs.org
Cc: kvm@vger.kernel.org
Cc: linux-s390@vger.kernel.org
Cc: linux-sgx@vger.kernel.org
Cc: intel-gfx@lists.freedesktop.org
Cc: dri-devel@lists.freedesktop.org
Cc: linux-rdma@vger.kernel.org
Cc: bpf@vger.kernel.org
Cc: linux-perf-users@vger.kernel.org
Cc: linux-fsdevel@vger.kernel.org
Cc: netdev@vger.kernel.org
Cc: rust-for-linux@vger.kernel.org
Cc: x86@kernel.org


David Hildenbrand (Arm) (16):
  mm/madvise: drop range checks in madvise_free_single_vma()
  mm/memory: remove "zap_details" parameter from zap_page_range_single()
  mm/memory: inline unmap_mapping_range_vma() into
    unmap_mapping_range_tree()
  mm/memory: simplify calculation in unmap_mapping_range_tree()
  mm/oom_kill: use MMU_NOTIFY_CLEAR in __oom_reap_task_mm()
  mm/oom_kill: factor out zapping of VMA into zap_vma_for_reaping()
  mm/memory: rename unmap_single_vma() to __zap_vma_range()
  mm/memory: move adjusting of address range to unmap_vmas()
  mm/memory: convert details->even_cows into details->skip_cows
  mm/memory: use __zap_vma_range() in zap_vma_for_reaping()
  mm/memory: inline unmap_page_range() into __zap_vma_range()
  mm: rename zap_vma_pages() to zap_vma()
  mm: rename zap_page_range_single_batched() to zap_vma_range_batched()
  mm: rename zap_page_range_single() to zap_vma_range()
  mm: rename zap_vma_ptes() to zap_special_vma_range()
  mm/memory: support VM_MIXEDMAP in zap_special_vma_range()

 arch/powerpc/platforms/book3s/vas-api.c |   2 +-
 arch/powerpc/platforms/pseries/vas.c    |   2 +-
 arch/s390/mm/gmap_helpers.c             |   2 +-
 arch/x86/kernel/cpu/sgx/encl.c          |   2 +-
 drivers/android/binder/page_range.rs    |   4 +-
 drivers/android/binder_alloc.c          |   2 +-
 drivers/comedi/comedi_fops.c            |   2 +-
 drivers/gpu/drm/i915/i915_mm.c          |   4 +-
 drivers/infiniband/core/uverbs_main.c   |   6 +-
 drivers/misc/sgi-gru/grumain.c          |   2 +-
 include/linux/mm.h                      |  23 ++-
 kernel/bpf/arena.c                      |   3 +-
 kernel/events/core.c                    |   2 +-
 lib/vdso/datastore.c                    |   2 +-
 mm/internal.h                           |   7 +-
 mm/interval_tree.c                      |   5 -
 mm/madvise.c                            |  24 +--
 mm/memory.c                             | 217 ++++++++++++------------
 mm/oom_kill.c                           |  15 +-
 mm/page-writeback.c                     |   2 +-
 net/ipv4/tcp.c                          |   7 +-
 rust/kernel/mm/virt.rs                  |   4 +-
 22 files changed, 162 insertions(+), 177 deletions(-)

----------------------------------------------------------------------

New:  util/update_headers: Update linux/const.h from linux sources
[kvmtool PATCH v6 01/17] util/update_headers: Update linux/const.h from linux sources
Author: Suzuki K Poulose <suzuki.poulose@arm.com>

Building kvmtool from scratch gives me the following errors with buildroot:

In file included from include/kvm/pci.h:7,
                 from include/kvm/vfio.h:6,
                 from include/kvm/kvm-config.h:5,
                 from include/kvm/kvm.h:6,
                 from builtin-version.c:4:
include/linux/virtio_pci.h:323:20: warning: implicit declaration of function ‘__KERNEL_DIV_ROUND_UP’ [-Wimplicit-function-declaration]
  323 | #define MAX_CAP_ID __KERNEL_DIV_ROUND_UP(VIRTIO_DEV_PARTS_CAP + 1, 64)
      |                    ^~~~~~~~~~~~~~~~~~~~~
include/linux/virtio_pci.h:326:24: note: in expansion of macro ‘MAX_CAP_ID’
  326 |  __le64 supported_caps[MAX_CAP_ID];
      |                        ^~~~~~~~~~
include/linux/virtio_pci.h:326:9: error: variably modified ‘supported_caps’ at file scope
  326 |  __le64 supported_caps[MAX_CAP_ID];

We inherit linux/virtio_pci.h from the kernel sources and won't be good to fix
it by including linux/kernel.h. Instead, pick up up uapi/linux/const.h from the
kernel tree. This also removes the ifdefery linux/kernel.h

To prevent a build warning for redefinition, update the headers from v6.19,
remove the hack from linux.kernel.h in one shot. This was also discussed in
the Link, in another context.

Cc: Anup Patel <apatel@ventanamicro.com>
Cc: Will Deacon <will@kernel.org>
Link: https://lore.kernel.org/all/20250211114018.GB8965@willie-the-truck/
Signed-off-by: Suzuki K Poulose <suzuki.poulose@arm.com>
---
 include/linux/const.h  | 53 ++++++++++++++++++++++++++++++++++++++++++
 include/linux/kernel.h |  3 ---
 util/update_headers.sh |  1 +
 3 files changed, 54 insertions(+), 3 deletions(-)

----------------------------------------------------------------------

New:  kvmtool: arm64: Handle PSCI calls in userspace
[kvmtool PATCH v6 00/17] kvmtool: arm64: Handle PSCI calls in userspace
Author: Suzuki K Poulose <suzuki.poulose@arm.com>

This is version 6 of the patch series, originally posted by Oliver [0].

Use SMCCC filtering capability in to handle PSCI calls in the userspace.

Changes since v5:
Link: https://lkml.kernel.org/r/20260108175753.1292097-1-suzuki.poulose@arm.com
 - Fix build break by importing linux/const.h from Linux UAP headers
 - Clean up the util/update_headers, issue warning for missing files.
 - Fix the psci.h source to Linux UAPI headers.
 - Rebased to Linux headers v6.19 (to match the tip of the tree)

Changes since v4:
Link: https://lkml.kernel.org/r/20250930103130.197534-1-suzuki.poulose@arm.com

 - Update headers to v6.18
 - Remove duplicate assignment of pause_req_cpu (Marc)
 - Flip the command line to opt in for PSCI in userspace, retaining default
   in kernel handling. (Marc)
 - Collect Review from Marc, thanks!

Changes since v3:
 - Address Will's comment on the race between pause/resume - Patch 1
 - Rebase on to v6.17-rc7
 - Drop importing cputype.h, which was not used by the series

[0] https://lore.kernel.org/all/20230802234255.466782-1-oliver.upton@linux.dev/


Oliver Upton (12):
  Import arm-smccc.h from Linux v6.19
  arm64: Stash kvm_vcpu_init for later use
  arm64: Use KVM_SET_MP_STATE ioctl to power off non-boot vCPUs
  arm64: Expose ARM64_CORE_REG() for general use
  arm64: Add support for finding vCPU for given MPIDR
  arm64: Add skeleton implementation for PSCI
  arm64: psci: Implement CPU_SUSPEND
  arm64: psci: Implement CPU_ON
  arm64: psci: Implement AFFINITY_INFO
  arm64: psci: Implement MIGRATE_INFO_TYPE
  arm64: psci: Implement SYSTEM_{OFF,RESET}
  arm64: smccc: Start sending PSCI to userspace

Suzuki K Poulose (5):
  util/update_headers: Update linux/const.h from linux sources
  util/update_headers: Clean up header copying
  util/update_headers: Warn about missing header files
  update_headers: arm64: Track uapi/linux/psci.h for PSCI definitions
  arm64: Sync headers from Linux v6.19 for psci.h

 Makefile                            |   2 +
 arm64/include/asm/smccc.h           |  65 ++++++
 arm64/include/kvm/kvm-arch.h        |   2 +
 arm64/include/kvm/kvm-config-arch.h |   8 +-
 arm64/include/kvm/kvm-cpu-arch.h    |  30 ++-
 arm64/kvm-cpu.c                     |  51 +++--
 arm64/kvm.c                         |  20 ++
 arm64/psci.c                        | 207 +++++++++++++++++++
 arm64/smccc.c                       |  81 ++++++++
 include/linux/arm-smccc.h           | 305 ++++++++++++++++++++++++++++
 include/linux/const.h               |  53 +++++
 include/linux/kernel.h              |   3 -
 include/linux/psci.h                |  52 +++++
 kvm-cpu.c                           |  13 ++
 util/update_headers.sh              |  23 ++-
 15 files changed, 874 insertions(+), 41 deletions(-)

----------------------------------------------------------------------

New:  support FEAT_LSUI
[PATCH v15 0/8] support FEAT_LSUI
Author: Yeoreum Yun <yeoreum.yun@arm.com>

Since Armv9.6, FEAT_LSUI supplies the load/store instructions for
previleged level to access to access user memory without clearing
PSTATE.PAN bit.

This patchset support FEAT_LSUI and applies it mainly in
futex atomic operation and others.

This patch based on v7.0-rc1


Patch History
==============
from v14 to v15:
  - replace caslt to cast
  - cleanup the patch
  - https://lore.kernel.org/all/20260225182708.3225211-1-yeoreum.yun@arm.com/

from v13 to v14:
  - add LSUI config check in cpucap_is_possible()
  - fix build failure with clang-19
  - https://lore.kernel.org/all/20260223174802.458411-1-yeoreum.yun@arm.com/

from v12 to v13:
  - rebase to v7.0-rc1
  - apply CASLT for swapping guest descriptor
  - remove has_lsui() for checking cpu feature.
  - simplify __lsui_cmpxchg32() according to @Catalin's suggestion.
  - use uaccess_ttbr0_enable()/disable() for LSUI instructions.
  - https://lore.kernel.org/all/aYWuqTqM5MvudI5V@e129823.arm.com/

from v11 to v12:
  - rebase to v6.19-rc6
  - add CONFIG_ARM64_LSUI
  - enable LSUI when !CPU_BIG_ENDIAN and PAN presents.
  - drop the swp emulation with LSUI insns instead, disable it
    when LSUI presents.
  - some of small fixes (useless prefix and suffix and etc).
  - https://lore.kernel.org/all/20251214112248.901769-1-yeoreum.yun@arm.com/

from v10 to v11:
  - rebase to v6.19-rc1
  - use cast instruction to emulate deprecated swpb instruction
  - https://lore.kernel.org/all/20251103163224.818353-1-yeoreum.yun@arm.com/

from v9 to v10:
  - apply FEAT_LSUI to user_swpX emulation.
  - add test coverage for LSUI bit in ID_AA64ISAR3_EL1
  - rebase to v6.18-rc4
  - https://lore.kernel.org/all/20250922102244.2068414-1-yeoreum.yun@arm.com/

from v8 to v9:
  - refotoring __lsui_cmpxchg64()
  - rebase to v6.17-rc7
  - https://lore.kernel.org/all/20250917110838.917281-1-yeoreum.yun@arm.com/

from v7 to v8:
  - implements futex_atomic_eor() and futex_atomic_cmpxchg() with casalt
    with C helper.
  - Drop the small optimisation on ll/sc futex_atomic_set operation.
  - modify some commit message.
  - https://lore.kernel.org/all/20250816151929.197589-1-yeoreum.yun@arm.com/

from v6 to v7:
  - wrap FEAT_LSUI with CONFIG_AS_HAS_LSUI in cpufeature
  - remove unnecessary addition of indentation.
  - remove unnecessary mte_tco_enable()/disable() on LSUI operation.
  - https://lore.kernel.org/all/20250811163635.1562145-1-yeoreum.yun@arm.com/

from v5 to v6:
  - rebase to v6.17-rc1
  - https://lore.kernel.org/all/20250722121956.1509403-1-yeoreum.yun@arm.com/

from v4 to v5:
  - remove futex_ll_sc.h futext_lsui and lsui.h and move them to futex.h
  - reorganize the patches.
  - https://lore.kernel.org/all/20250721083618.2743569-1-yeoreum.yun@arm.com/

from v3 to v4:
  - rebase to v6.16-rc7
  - modify some patch's title.
  - https://lore.kernel.org/all/20250617183635.1266015-1-yeoreum.yun@arm.com/

from v2 to v3:
  - expose FEAT_LSUI to guest
  - add help section for LSUI Kconfig
  - https://lore.kernel.org/all/20250611151154.46362-1-yeoreum.yun@arm.com/

from v1 to v2:
  - remove empty v9.6 menu entry
  - locate HAS_LSUI in cpucaps in order
  - https://lore.kernel.org/all/20250611104916.10636-1-yeoreum.yun@arm.com/


Yeoreum Yun (8):
  arm64: cpufeature: add FEAT_LSUI
  KVM: arm64: expose FEAT_LSUI to guest
  KVM: arm64: kselftest: set_id_regs: add test for FEAT_LSUI
  arm64: futex: refactor futex atomic operation
  arm64: futex: support futex with FEAT_LSUI
  arm64: armv8_deprecated: disable swp emulation when FEAT_LSUI present
  KVM: arm64: use CAST instruction for swapping guest descriptor
  arm64: Kconfig: add support for LSUI

 arch/arm64/Kconfig                            |  20 ++
 arch/arm64/include/asm/cpucaps.h              |   2 +
 arch/arm64/include/asm/futex.h                | 297 +++++++++++++++---
 arch/arm64/include/asm/lsui.h                 |  27 ++
 arch/arm64/kernel/armv8_deprecated.c          |  16 +
 arch/arm64/kernel/cpufeature.c                |  10 +
 arch/arm64/kvm/at.c                           |  42 ++-
 arch/arm64/kvm/sys_regs.c                     |   3 +-
 arch/arm64/tools/cpucaps                      |   1 +
 .../testing/selftests/kvm/arm64/set_id_regs.c |   1 +
 10 files changed, 367 insertions(+), 52 deletions(-)

----------------------------------------------------------------------

New:  RISC-V: KVM: fix off-by-one array access in SBI PMU
[PATCH] RISC-V: KVM: fix off-by-one array access in SBI PMU
Author: Radim Krčmář <radim.krcmar@oss.qualcomm.com>

The indexed array only has RISCV_KVM_MAX_COUNTERS elements.
The out-of-bound access could have been performed by a guest, but it
could only access another guest accessible data.

Fixes: 8f0153ecd3bf ("RISC-V: KVM: Add skeleton support for perf")
Signed-off-by: Radim Krčmář <radim.krcmar@oss.qualcomm.com>
---
 arch/riscv/kvm/vcpu_pmu.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

----------------------------------------------------------------------

New:  PCI: Correct PCI_CAP_EXP_ENDPOINT_SIZEOF_V2 value
[PATCH] PCI: Correct PCI_CAP_EXP_ENDPOINT_SIZEOF_V2 value
Author: Bjorn Helgaas <helgaas@kernel.org>

fb82437fdd8c ("PCI: Change capability register offsets to hex") incorrectly
converted the PCI_CAP_EXP_ENDPOINT_SIZEOF_V2 value from decimal 52 to hex
0x32:

  -#define PCI_CAP_EXP_ENDPOINT_SIZEOF_V2 52      /* v2 endpoints with link end here */
  +#define PCI_CAP_EXP_ENDPOINT_SIZEOF_V2 0x32    /* end of v2 EPs w/ link */

Change PCI_CAP_EXP_ENDPOINT_SIZEOF_V2 to the correct value of 0x34.

fb82437fdd8c was from Baruch Siach <baruch@tkos.co.il>, but this was not
Baruch's fault; it's a mistake I made when applying the patch.

Fixes: fb82437fdd8c ("PCI: Change capability register offsets to hex")
Reported-by: David Woodhouse <dwmw2@infradead.org>
Closes: https://lore.kernel.org/all/3ae392a0158e9d9ab09a1d42150429dd8ca42791.camel@infradead.org
Signed-off-by: Bjorn Helgaas <bhelgaas@google.com>
---
 include/uapi/linux/pci_regs.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

----------------------------------------------------------------------

New:  KVM: x86: Move nested_run_pending to kvm_vcpu_arch
[PATCH 1/3] KVM: x86: Move nested_run_pending to kvm_vcpu_arch
Author: Yosry Ahmed <yosry@kernel.org>

Move nested_run_pending field present in both svm_nested_state and
nested_vmx to the common kvm_vcpu_arch. This allows for common code to
use without plumbing it through per-vendor helpers.

nested_run_pending remains zero-initialized, as the entire kvm_vcpu
struct is, and all further accesses are done through vcpu->arch instead
of svm->nested or vmx->nested.

No functional change intended.

Suggested-by: Sean Christopherson <seanjc@google.com>
Signed-off-by: Yosry Ahmed <yosry@kernel.org>
---
 arch/x86/include/asm/kvm_host.h |  3 +++
 arch/x86/kvm/svm/nested.c       | 14 +++++-----
 arch/x86/kvm/svm/svm.c          | 12 ++++-----
 arch/x86/kvm/svm/svm.h          |  4 ---
 arch/x86/kvm/vmx/nested.c       | 46 ++++++++++++++++-----------------
 arch/x86/kvm/vmx/vmx.c          | 16 ++++++------
 arch/x86/kvm/vmx/vmx.h          |  3 ---
 7 files changed, 47 insertions(+), 51 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86: Fix incorrect handling of triple faults
[PATCH 0/3] KVM: x86: Fix incorrect handling of triple faults
Author: Yosry Ahmed <yosry@kernel.org>

Fix a couple of bugs related to handling triple faults, namely KVM
injecting a triple fault into an L2 that hasn't run yet, or KVM
combining #DB/#BP from KVM_SET_GUEST_DEBUG with existing exceptions
causing a triple fault (or #DF).

Either of these bugs can result in a triple fault being injected with
nested_run_pending=1, leading to triggering the warning in
__nested_vmx_vmexit().

The following syzkaller reproducer should trigger it (although it was
manually modified and I cannot test it directly):

r0 = openat$kvm(0xffffffffffffff9c, &(0x7f0000000180), 0x2, 0x0)
r1 = ioctl$KVM_CREATE_VM(r0, 0xae01, 0x0)
r2 = ioctl$KVM_CREATE_VCPU(r1, 0xae41, 0x0)
r3 = ioctl$KVM_GET_VCPU_MMAP_SIZE(r0, 0xae04)
mmap$KVM_VCPU(&(0x7f0000fe9000/0x3000)=nil, r3, 0x1000003, 0x13, r2, 0x0)
syz_kvm_setup_cpu$x86(r1, r2, &(0x7f0000fe5000/0x18000)=nil, &(0x7f00000000c0)=[@text64={0x40, 0x0}], 0x1, 0x41, 0x0, 0x0)
ioctl$KVM_RUN(r2, 0xae80, 0x0)
ioctl$KVM_SET_VCPU_EVENTS(r2, 0x4040aea0, &(0x7f00000006c0)=@x86={0xf7, 0x8, 0x29, 0x0, 0x5, 0x67, 0x1, 0x9, 0x9, 0xbd, 0x6, 0xff, 0x0, 0x5, 0x4, 0x3, 0x7, 0x7, 0xc, '\x00', 0x7, 0xb})
ioctl$KVM_SET_GUEST_DEBUG_x86(r2, 0x4048ae9b, &(0x7f0000000100)={0x1d0002, 0x0, {[0x8, 0x0, 0x7, 0x2, 0x87c8, 0x5, 0x5, 0x6]}})
ioctl$KVM_RUN(r2, 0xae80, 0x0)

Yosry Ahmed (3):
  KVM: x86: Move nested_run_pending to kvm_vcpu_arch
  KVM: x86: Do not inject triple faults into an L2 with a pending run
  KVM: x86: Check for injected exceptions before queuing a debug
    exception

 arch/x86/include/asm/kvm_host.h |  3 +++
 arch/x86/kvm/svm/nested.c       | 14 +++++-----
 arch/x86/kvm/svm/svm.c          | 12 ++++-----
 arch/x86/kvm/svm/svm.h          |  4 ---
 arch/x86/kvm/vmx/nested.c       | 46 ++++++++++++++++-----------------
 arch/x86/kvm/vmx/vmx.c          | 16 ++++++------
 arch/x86/kvm/vmx/vmx.h          |  3 ---
 arch/x86/kvm/x86.c              | 15 ++++++++++-
 8 files changed, 61 insertions(+), 52 deletions(-)

----------------------------------------------------------------------

New:  linux/virtio_pci.h: Include kernel.h to provide the __KERNEL_DIV_ROUND_UP define
[PATCH kvmtool 1/1] linux/virtio_pci.h: Include kernel.h to provide the __KERNEL_DIV_ROUND_UP define
Author: hbuxiaofei <hbuxiaofei@gmail.com>

GCC Version:
  gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)

CC       builtin-balloon.o
In file included from include/kvm/pci.h:7:0,
                 from include/kvm/vfio.h:6,
                 from include/kvm/kvm-config.h:5,
                 from include/kvm/kvm.h:6,
                 from builtin-balloon.c:9:
include/linux/virtio_pci.h:326:2: error: implicit declaration of function ‘__KERNEL_DIV_ROUND_UP’ [-Werror=implicit-function-declaration]
  __le64 supported_caps[MAX_CAP_ID];
  ^
include/linux/virtio_pci.h:326:9: error: variably modified ‘supported_caps’ at file scope
  __le64 supported_caps[MAX_CAP_ID];
         ^
cc1: all warnings being treated as errors
make: *** [builtin-balloon.o] Error 1

Signed-off-by: hbuxiaofei <hbuxiaofei@gmail.com>
---
 include/linux/virtio_pci.h | 1 +
 1 file changed, 1 insertion(+)

----------------------------------------------------------------------

New:  KVM: x86/pmu: Do not map fixed counters >= 3 to generic perf events
[PATCH 1/3] KVM: x86/pmu: Do not map fixed counters >= 3 to generic perf events
Author: Zide Chen <zide.chen@intel.com>

Only fixed counters 0..2 have matching generic cross-platform
hardware perf events (INSTRUCTIONS, CPU_CYCLES, REF_CPU_CYCLES).
Therefore, perf_get_hw_event_config() is only applicable to these
counters.

KVM does not intend to emulate fixed counters >= 3 on legacy
(non-mediated) vPMU, while for mediated vPMU, KVM does not care what
the fixed counter event mappings are.  Therefore, return 0 for their
eventsel.

Also remove __always_inline as BUILD_BUG_ON() is no longer needed.

Signed-off-by: Zide Chen <zide.chen@intel.com>
---
 arch/x86/kvm/vmx/pmu_intel.c | 26 ++++++++++++++------------
 1 file changed, 14 insertions(+), 12 deletions(-)

----------------------------------------------------------------------

New:  KVM: x86/pmu: Add hardware Topdown metrics support
[PATCH 0/3] KVM: x86/pmu: Add hardware Topdown metrics support
Author: Zide Chen <zide.chen@intel.com>

The Top-Down Microarchitecture Analysis (TMA) method is a structured
approach for identifying performance bottlenecks in out-of-order
processors.

Currently, guests support the TMA method by collecting Topdown events
using GP counters, which may trigger multiplexing.  To free up scarce
GP counters, eliminate multiplexing-induced skew, and obtain coherent
Topdown metric ratios, it is desirable to expose fixed counter 3 and
the IA32_PERF_METRICS MSR to guests.

Several failed attempts have been made to virtualize this under the
legacy vPMU model: [1], [2], [3].  With the new mediated vPMU, enabling
TMA support in guests becomes much simpler.  It avoids invasive changes
to the perf core, eliminates CPU pinning and fixed-counter affinity
issues, and reduces the overhead of trapping and emulating MSR accesses.

[1] https://lore.kernel.org/kvm/20231031090613.2872700-1-dapeng1.mi@linux.intel.com/
[2] https://lore.kernel.org/all/20230927033124.1226509-1-dapeng1.mi@linux.intel.com/T/
[3] https://lwn.net/ml/linux-kernel/20221212125844.41157-1-likexu@tencent.com/

Tested on an SPR.  Without this series, only raw topdown.*_slots events
work in the guest, and metric events (e.g. cpu/topdown-bad-spec/) are
not available.

With this series, metric events are visible in the guest.  Run this
command on both host and guest:

$ perf stat --topdown --no-metric-only -- taskset -c 2 perf bench sched messaging

Host results:

# Running 'sched/messaging' benchmark:
# 20 sender and receiver processes per group
# 10 groups == 400 processes run

     Total time: 1.500 [sec]

 Performance counter stats for 'taskset -c 2 perf bench sched messaging':

     4,266,060,558      TOPDOWN.SLOTS:u              #     32.0 %  tma_frontend_bound
                                                     #      5.2 %  tma_bad_speculation
       588,397,905      topdown-retiring:u           #     13.8 %  tma_retiring
                                                     #     49.0 %  tma_backend_bound
     1,376,283,990      topdown-fe-bound:u
     2,096,827,304      topdown-be-bound:u
       217,425,841      topdown-bad-spec:u
         5,050,520      INT_MISC.UOP_DROPPING:u

       1.755503765 seconds time elapsed

       0.235965000 seconds user
       1.500508000 seconds sys

Guest results:

# Running 'sched/messaging' benchmark:
# 20 sender and receiver processes per group
# 10 groups == 400 processes run

     Total time: 1.558 [sec]

 Performance counter stats for 'taskset -c 2 perf bench sched messaging':

     5,148,818,712      TOPDOWN.SLOTS:u              #     34.0 %  tma_frontend_bound
                                                     #      4.6 %  tma_bad_speculation
       602,862,499      topdown-retiring:u           #     11.7 %  tma_retiring
                                                     #     49.7 %  tma_backend_bound
     1,759,698,259      topdown-fe-bound:u
     2,565,571,672      topdown-be-bound:u
       230,277,308      topdown-bad-spec:u
         4,966,279      INT_MISC.UOP_DROPPING:u

       1.783366587 seconds time elapsed

       0.313692000 seconds user
       1.446377000 seconds sys

Dapeng Mi (2):
  KVM: x86/pmu: Support Intel fixed counter 3 on mediated vPMU
  KVM: x86/pmu: Support PERF_METRICS MSR in mediated vPMU

Zide Chen (1):
  KVM: x86/pmu: Do not map fixed counters >= 3 to generic perf events

 arch/x86/include/asm/kvm_host.h   |  3 +-
 arch/x86/include/asm/msr-index.h  |  1 +
 arch/x86/include/asm/perf_event.h |  1 +
 arch/x86/kvm/pmu.c                |  4 +++
 arch/x86/kvm/vmx/pmu_intel.c      | 57 ++++++++++++++++++++++++-------
 arch/x86/kvm/vmx/pmu_intel.h      |  5 +++
 arch/x86/kvm/vmx/vmx.c            |  6 ++++
 arch/x86/kvm/x86.c                | 10 ++++--
 8 files changed, 71 insertions(+), 16 deletions(-)

----------------------------------------------------------------------

