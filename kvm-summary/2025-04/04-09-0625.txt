From 72084f86 to d88ded5c
KVM mailing list update from 72084f86 to d88ded5c

Top 15 contributor Email domains (Based on Email Body)

     25 kernel.org
     13 amd.com
      2 linaro.org
      1 nvidia.com
      1 meta.com
      1 google.com
      1 arm.com

Top 15 contributors (Based on Email Body)

     18  Marc Zyngier <maz@kernel.org>
      7  Shivank Garg <shivankg@amd.com>
      7  Josh Poimboeuf <jpoimboe@kernel.org>
      4  Nikunj A Dadhania <nikunj@amd.com>
      2  Jean-Philippe Brucker <jean-philippe@linaro.org>
      1  Shivansh Dhiman <shivansh.dhiman@amd.com>
      1  Ketan Chaturvedi <Ketan.Chaturvedi@amd.com>
      1  Joshua Lilly <jgl@meta.com>
      1  Jason Gunthorpe <jgg@nvidia.com>
      1  Alexandru Elisei <alexandru.elisei@arm.com>
      1  Ackerley Tng <ackerleytng@google.com>

===== Patch list in this time period =====


===== Patch Commit Messages ====

New:  x86/bugs: Rename entry_ibpb() to write_ibpb()
[PATCH v4 1/6] x86/bugs: Rename entry_ibpb() to write_ibpb()
Author: Josh Poimboeuf <jpoimboe@kernel.org>

There's nothing entry-specific about entry_ibpb().  In preparation for
calling it from elsewhere, rename it to write_ibpb().

Signed-off-by: Josh Poimboeuf <jpoimboe@kernel.org>
---
 arch/x86/entry/entry.S               | 7 ++++---
 arch/x86/include/asm/nospec-branch.h | 6 +++---
 arch/x86/kernel/cpu/bugs.c           | 6 +++---
 3 files changed, 10 insertions(+), 9 deletions(-)

----------------------------------------------------------------------

New:  x86/bugs: RSB mitigation fixes and documentation
[PATCH v4 0/6] x86/bugs: RSB mitigation fixes and documentation
Author: Josh Poimboeuf <jpoimboe@kernel.org>

v4:
- improve document
- remove C++ comment
- "__write_ibpb" -> "write-ibpb"
- improve commit logs

v3: https://lore.kernel.org/cover.1743617897.git.jpoimboe@kernel.org

Josh Poimboeuf (6):
  x86/bugs: Rename entry_ibpb() to write_ibpb()
  x86/bugs: Use SBPB in write_ibpb() if applicable
  x86/bugs: Fix RSB clearing in indirect_branch_prediction_barrier()
  x86/bugs: Don't fill RSB on VMEXIT with eIBRS+retpoline
  x86/bugs: Don't fill RSB on context switch with eIBRS
  x86/bugs: Add RSB mitigation document

 Documentation/admin-guide/hw-vuln/index.rst |   1 +
 Documentation/admin-guide/hw-vuln/rsb.rst   | 268 ++++++++++++++++++++
 arch/x86/entry/entry.S                      |   9 +-
 arch/x86/include/asm/nospec-branch.h        |  12 +-
 arch/x86/kernel/cpu/bugs.c                  | 107 +++-----
 arch/x86/mm/tlb.c                           |   6 +-
 6 files changed, 317 insertions(+), 86 deletions(-)

----------------------------------------------------------------------

New:  vfio/type1: Remove Fine Grained Superpages detection
[PATCH] vfio/type1: Remove Fine Grained Superpages detection
Author: Jason Gunthorpe <jgg@nvidia.com>

VFIO is looking to enable an optimization where it can rely on the
unmap operation not splitting and returning the size of a larger IOPTE.

However since commits:
  d50651636fb ("iommu/io-pgtable-arm-v7s: Remove split on unmap behavior")
  33729a5fc0ca ("iommu/io-pgtable-arm: Remove split on unmap behavior")

There are no iommu drivers that do split on unmap anymore. Instead all
iommu drivers are expected to unmap the whole contiguous page and return
its size.

Thus, there is no purpose in vfio_test_domain_fgsp() as it is only
checking if the iommu supports 2*PAGE_SIZE as a contiguous page or not.

Currently only AMD v1 supports such a page size so all this logic only
activates on AMD v1.

Remove vfio_test_domain_fgsp() and just rely on a direct 2*PAGE_SIZE check
instead so there is no behavior change.

Maybe it should always activate the iommu_iova_to_phys(), it shouldn't
have a performance downside since split is gone.

Signed-off-by: Jason Gunthorpe <jgg@nvidia.com>
---
 drivers/vfio/vfio_iommu_type1.c | 71 +++++++++------------------------
 1 file changed, 19 insertions(+), 52 deletions(-)

----------------------------------------------------------------------

New:  Add I/O port filtering for AMDs sev module.
[PATCH] Add I/O port filtering for AMDs sev module.
Author: Joshua Lilly <jgl@meta.com>

This adds a port allow list to allow PCIE, ACPI, PCI, DMA,
RTC, etc and serial for easy debugging when debugging is enabled.
The port allow list (switch statement) is copied directly from
the tdx code.

Reviewed-by: Keith Busch <kbusch@kernel.org>
Signed-off-by: Joshua Lilly <jgl@meta.com>
---
 arch/x86/coco/sev/core.c   |  3 +++
 arch/x86/coco/sev/shared.c | 41 ++++++++++++++++++++++++++++++++++++++
 2 files changed, 44 insertions(+)

----------------------------------------------------------------------

New:  arm64: Change the default QEMU CPU type to "max
[kvm-unit-tests PATCH v4 0/5] arm64: Change the default QEMU CPU type to "max
Author: Jean-Philippe Brucker <jean-philippe@linaro.org>

This is v4 of the series that cleans up the configure flags and sets the
default CPU type to "max" on arm64, in order to test the latest Arm
features.

Since v3 [1] I renamed --qemu-cpu to --target-cpu, to prepare for other
VMMs.

[1] https://lore.kernel.org/all/20250325160031.2390504-3-jean-philippe@linaro.org/


Alexandru Elisei (3):
  configure: arm64: Don't display 'aarch64' as the default architecture
  configure: arm/arm64: Display the correct default processor
  arm64: Implement the ./configure --processor option

Jean-Philippe Brucker (2):
  configure: Add --target-cpu option
  arm64: Use -cpu max as the default for TCG

 scripts/mkstandalone.sh |  3 ++-
 arm/run                 | 15 ++++++-----
 riscv/run               |  8 +++---
 configure               | 55 +++++++++++++++++++++++++++++++++++------
 arm/Makefile.arm        |  1 -
 arm/Makefile.common     |  1 +
 6 files changed, 63 insertions(+), 20 deletions(-)

----------------------------------------------------------------------

New:  mm/filemap: Add mempolicy support to the filemap layer
[PATCH RFC v7 1/8] mm/filemap: Add mempolicy support to the filemap layer
Author: Shivank Garg <shivankg@amd.com>


Add NUMA mempolicy support to the filemap allocation path by introducing
new APIs that take a mempolicy argument:
- filemap_grab_folio_mpol()
- filemap_alloc_folio_mpol()
- __filemap_get_folio_mpol()

These APIs allow callers to specify a NUMA policy during page cache
allocations, enabling fine-grained control over memory placement. This is
particularly needed by KVM when using guest-memfd memory backends, where
the guest memory needs to be allocated according to the NUMA policy
specified by VMM.

The existing non-mempolicy APIs remain unchanged and continue to use the
default allocation behavior.

Signed-off-by: Shivansh Dhiman <shivansh.dhiman@amd.com>
Signed-off-by: Shivank Garg <shivankg@amd.com>
---
 include/linux/pagemap.h | 41 +++++++++++++++++++++++++++++++++++++++++
 mm/filemap.c            | 27 +++++++++++++++++++++++----
 2 files changed, 64 insertions(+), 4 deletions(-)

----------------------------------------------------------------------

New:  Add NUMA mempolicy support for KVM guest-memfd
[PATCH RFC v7 0/8] Add NUMA mempolicy support for KVM guest-memfd
Author: Shivank Garg <shivankg@amd.com>

KVM's guest-memfd memory backend currently lacks support for NUMA policy
enforcement, causing guest memory allocations to be distributed arbitrarily
across host NUMA nodes regardless of the policy specified by the VMM. This
occurs because conventional userspace NUMA control mechanisms like mbind()
are ineffective with guest-memfd, as the memory isn't directly mapped to
userspace when allocations occur.

This patch-series adds NUMA-aware memory placement for guest_memfd backed
KVM guests. Based on community feedback, the approach has evolved as
follows:

- v1,v2: Extended the KVM_CREATE_GUEST_MEMFD IOCTL to pass mempolicy.
- v3: Introduced fbind() syscall for VMM memory-placement configuration.
- v4-v6: Current approach using shared_policy support and vm_ops (based on
         suggestions from David[1] and guest_memfd biweekly upstream
         calls[2][4]).
- v7: Use inodes to store NUMA policy instead of file[5].

== Implementation ==

This series implements proper NUMA policy support for guest-memfd by:

1. Adding mempolicy-aware allocation APIs to the filemap layer.
2. Add custom inodes (via a dedicated slab-allocated inode cache,
   kvm_gmem_inode_info) to store NUMA policy and metadata for guest memory.
3. Implementing get/set_policy vm_ops in guest_memfd to support shared policy.

With these changes, VMMs can now control guest memory placement by
specifying:
- Policy modes: default, bind, interleave, or preferred
- Host NUMA nodes: List of target nodes for memory allocation

Policies only affect future allocations and do not migrate existing memory.
This matches mbind(2)'s default behavior which affects only new allocations
unless overridden with MPOL_MF_MOVE/MPOL_MF_MOVE_ALL flags (Not supported
for guest_memfd as it is unmovable).

This series builds on the existing guest-memfd support in KVM and provides
a clean integration path for NUMA-aware memory management in confidential
computing environments. The work is primarily focused on supporting SEV-SNP
requirements, though the benefits extend to any VMM using the guest-memfd
backend that needs control over guest memory placement.

== Example usage with QEMU (requires patched QEMU from [3]) ==

Snippet of the QEMU changes[3] needed to support this feature:

        /* Create and map guest-memfd region */
        new_block->guest_memfd = kvm_create_guest_memfd(
                                  new_block->max_length, 0, errp);
...
        void *ptr_memfd = mmap(NULL, new_block->max_length,
                               PROT_READ | PROT_WRITE, MAP_SHARED,
                               new_block->guest_memfd, 0);
...
        /* Apply NUMA policy */
        int ret = mbind(ptr_memfd, new_block->max_length,
                        backend->policy, backend->host_nodes,
                        maxnode+1, 0);
...

QEMU Command to run SEV-SNP guest with interleaved memory across
nodes 0 and 1 of the host:

$ qemu-system-x86_64 \
   -enable-kvm \
  ...
   -machine memory-encryption=sev0,vmport=off \
   -object sev-snp-guest,id=sev0,cbitpos=51,reduced-phys-bits=1 \
   -numa node,nodeid=0,memdev=ram0,cpus=0-15 \
   -object memory-backend-memfd,id=ram0,host-nodes=0-1,policy=interleave,size=1024M,share=true,prealloc=false

== Experiment and Analysis == 

SEV-SNP enabled host, AMD Zen 3, 2 socket 2 NUMA node system
NUMA for Policy Guest Node 0: policy=interleave, host-node=0-1

Test: Allocate and touch 50GB inside guest on node=0.


* Generic Kernel (without NUMA supported guest-memfd):
                          Node 0          Node 1           Total
Before running Test:
MemUsed                  9981.60         3312.00        13293.60
After running Test:
MemUsed                 61451.72         3201.62        64653.34

Arbitrary allocations: all ~50GB allocated on node 0.


* With NUMA supported guest-memfd:
                          Node 0          Node 1           Total
Before running Test:
MemUsed                  5003.88         3963.07         8966.94
After running Test:
MemUsed                 30607.55        29670.00        60277.55

Balanced memory distribution: Equal increase (~25GB) on both nodes.

== Conclusion ==

Adding the NUMA-aware memory management to guest_memfd will make a lot of
sense. Improving performance of memory-intensive and locality-sensitive
workloads with fine-grained control over guest memory allocations, as
pointed out in the analysis.

Please review and provide feedback!

Thanks,
Shivank

[1] https://lore.kernel.org/all/6fbef654-36e2-4be5-906e-2a648a845278@redhat.com
[2] https://lore.kernel.org/all/6f2bfac2-d9e7-4e4a-9298-7accded16b4f@redhat.com
[3] https://github.com/shivankgarg98/qemu/tree/guest_memfd_mbind_NUMA
[4] https://lore.kernel.org/all/2b77e055-98ac-43a1-a7ad-9f9065d7f38f@amd.com
[5] https://lore.kernel.org/all/diqzbjumm167.fsf@ackerleytng-ctop.c.googlers.com

== Earlier postings and changelogs ==

v7 (current):
- Add fixes suggested by Vlastimil and Ackerley.
- Store NUMA policy in custom inode struct instead of file.

v6:
- https://lore.kernel.org/all/20250226082549.6034-1-shivankg@amd.com
- Rebase to linux mainline
- Drop RFC tag
- Add selftests to ensure NUMA support for guest_memfd works correctly.

v5:
- https://lore.kernel.org/all/20250219101559.414878-1-shivankg@amd.com
- Fix documentation and style issues.
- Use EXPORT_SYMBOL_GPL
- Split preparatory change in separate patch

v4:
- https://lore.kernel.org/all/20250210063227.41125-1-shivankg@amd.com
- Dropped fbind() approach in favor of shared policy support.

v3:
- https://lore.kernel.org/all/20241105164549.154700-1-shivankg@amd.com
- Introduce fbind() syscall and drop the IOCTL-based approach.

v2:
- https://lore.kernel.org/all/20240919094438.10987-1-shivankg@amd.com
- Add fixes suggested by Matthew Wilcox.

v1:
- https://lore.kernel.org/all/20240916165743.201087-1-shivankg@amd.com
- Proposed IOCTL based approach to pass NUMA mempolicy.

Ackerley Tng (1):
  KVM: guest_memfd: Make guest mem use guest mem inodes instead of
    anonymous inodes

Shivank Garg (6):
  mm/mempolicy: Export memory policy symbols
  security: Export security_inode_init_security_anon for KVM guest_memfd
  KVM: Add kvm_gmem_exit() cleanup function
  KVM: guest_memfd: Add slab-allocated inode cache
  KVM: guest_memfd: Enforce NUMA mempolicy using shared policy
  KVM: guest_memfd: selftests: Add tests for mmap and NUMA policy
    support

Shivansh Dhiman (1):
  mm/filemap: Add mempolicy support to the filemap layer

 include/linux/pagemap.h                       |  41 +++
 include/uapi/linux/magic.h                    |   1 +
 mm/filemap.c                                  |  27 +-
 mm/mempolicy.c                                |   6 +
 security/security.c                           |   1 +
 .../testing/selftests/kvm/guest_memfd_test.c  |  86 +++++-
 virt/kvm/guest_memfd.c                        | 261 ++++++++++++++++--
 virt/kvm/kvm_main.c                           |   2 +
 virt/kvm/kvm_mm.h                             |   6 +
 9 files changed, 402 insertions(+), 29 deletions(-)

----------------------------------------------------------------------

New:  KVM: arm64: Recursive NV support
[PATCH v2 00/17] KVM: arm64: Recursive NV support
Author: Marc Zyngier <maz@kernel.org>

KVM: arm64: Recursive NV support

This is probably the most interesting bit of the whole NV adventure.
So far, everything else has been a walk in the park, but this one is
where the real fun takes place.

With FEAT_NV2, most of the NV support revolves around tricking a guest
into accessing memory while it tries to access system registers. The
hypervisor's job is to handle the context switch of the actual
registers with the state in memory as needed.

This memory (which we shall call the VNCR page henceforth) lives at an
EL2 VA, and is therefore accessed out of context by the EL1 guest
hypervisor.

So far, so good. But what does it mean to virtualise VNCR itself?

It means that when L1 has a prepared a VNCR page for L2, we must map
it in the L0 EL2, and allow L2 to magically access it. Isn't that fun?
To some extent. But there's more!

Having that L0 mapping on behalf of L1 comes with strings attached. It
means that we must be prepared for this page to become inaccessible,
which can happen for a variety of reasons:

- paged out from the host (MMU notifiers)

- unmapped from L1 EL2 stage-1

- permission changes in L1 EL2 stage-1

And in case you're wondering, yes, all of these have TLB invalidation
in common. That's because performing this mapping is akin to
allocating a "SW managed" TLB for L1's VNCR page.

This is what the bulk of this series is about: TLB management for VNCR
pages, and making sure we have the correct page at the right time.

From an implementation perspective, it isn't that complicated, as it
plugs into the existing NV artillery (TLBI, AT, MMU notifiers). Of
course, nothing is optimised, because we're not at this stage yet. I
have plans to make this better (i.e. fewer TLBIs, which implies fewer
traps when nesting), but that's all future work.

But this is functional enough that I can run an L4 guest on my QC
box. Slowly.

As an added bonus, this series now includes the last two patches that
switch the damned thing on. Does it mean this is bug-free? Of course
not. But we're at a point where NV is no longer a third-rate citizen.
Only a second-rate one.

Patches on top of v6.15-rc1. The full integration is, as always, in my
kvm-arm64/nv-next branch.

* From v1:

  - Rebased on 6.15-rc1

  - Picked up the last two patches to enable the full NV shebang

[1] https://lore.kernel.org/r/20250215150134.3765791-10-maz@kernel.org

Marc Zyngier (17):
  arm64: sysreg: Add layout for VNCR_EL2
  KVM: arm64: nv: Allocate VNCR page when required
  KVM: arm64: nv: Extract translation helper from the AT code
  KVM: arm64: nv: Snapshot S1 ASID tagging information during walk
  KVM: arm64: nv: Move TLBI range decoding to a helper
  KVM: arm64: nv: Don't adjust PSTATE.M when L2 is nesting
  KVM: arm64: nv: Add pseudo-TLB backing VNCR_EL2
  KVM: arm64: nv: Add userspace and guest handling of VNCR_EL2
  KVM: arm64: nv: Handle VNCR_EL2-triggered faults
  KVM: arm64: nv: Handle mapping of VNCR_EL2 at EL2
  KVM: arm64: nv: Handle VNCR_EL2 invalidation from MMU notifiers
  KVM: arm64: nv: Program host's VNCR_EL2 to the fixmap address
  KVM: arm64: nv: Add S1 TLB invalidation primitive for VNCR_EL2
  KVM: arm64: nv: Plumb TLBI S1E2 into system instruction dispatch
  KVM: arm64: nv: Remove dead code from ERET handling
  KVM: arm64: Allow userspace to request KVM_ARM_VCPU_EL2*
  KVM: arm64: Document NV caps and vcpu flags

 Documentation/virt/kvm/api.rst      |  14 +-
 arch/arm64/include/asm/esr.h        |   2 +
 arch/arm64/include/asm/fixmap.h     |   6 +
 arch/arm64/include/asm/kvm_host.h   |  15 +-
 arch/arm64/include/asm/kvm_nested.h | 100 +++++
 arch/arm64/include/asm/sysreg.h     |   1 -
 arch/arm64/kvm/arm.c                |  10 +
 arch/arm64/kvm/at.c                 | 123 +++---
 arch/arm64/kvm/emulate-nested.c     |   7 -
 arch/arm64/kvm/handle_exit.c        |   1 +
 arch/arm64/kvm/hyp/vhe/switch.c     |  46 ++-
 arch/arm64/kvm/nested.c             | 608 +++++++++++++++++++++++++++-
 arch/arm64/kvm/reset.c              |   2 +
 arch/arm64/kvm/sys_regs.c           | 135 +++---
 arch/arm64/tools/sysreg             |   6 +
 include/uapi/linux/kvm.h            |   2 +
 16 files changed, 940 insertions(+), 138 deletions(-)

----------------------------------------------------------------------

New:  arm64: sysreg: Add layout for VNCR_EL2
[PATCH v2 01/17] arm64: sysreg: Add layout for VNCR_EL2
Author: Marc Zyngier <maz@kernel.org>

Now that we're about to emulate VNCR_EL2, we need its full layout.
Add it to the sysreg file.

Signed-off-by: Marc Zyngier <maz@kernel.org>
---
 arch/arm64/include/asm/sysreg.h | 1 -
 arch/arm64/tools/sysreg         | 6 ++++++
 2 files changed, 6 insertions(+), 1 deletion(-)

----------------------------------------------------------------------

New:  x86/cpufeatures: Add SNP Secure TSC
[PATCH v6 1/4] x86/cpufeatures: Add SNP Secure TSC
Author: Nikunj A Dadhania <nikunj@amd.com>

The Secure TSC feature for SEV-SNP allows guests to securely use the RDTSC
and RDTSCP instructions, ensuring that the parameters used cannot be
altered by the hypervisor once the guest is launched. For more details,
refer to the AMD64 APM Vol 2, Section "Secure TSC".

Acked-by: Borislav Petkov (AMD) <bp@alien8.de>
Reviewed-by: Tom Lendacky <thomas.lendacky@amd.com>
Tested-by: Vaishali Thakkar <vaishali.thakkar@suse.com>
Signed-off-by: Nikunj A Dadhania <nikunj@amd.com>
---
 arch/x86/include/asm/cpufeatures.h | 1 +
 1 file changed, 1 insertion(+)

----------------------------------------------------------------------

New:  Enable Secure TSC for SEV-SNP
[PATCH v6 0/4] Enable Secure TSC for SEV-SNP
Author: Nikunj A Dadhania <nikunj@amd.com>

The hypervisor controls TSC value calculations for the guest. A malicious
hypervisor can prevent the guest from progressing. The Secure TSC feature for
SEV-SNP allows guests to securely use the RDTSC and RDTSCP instructions. This
ensures the guest has a consistent view of time and prevents a malicious
hypervisor from manipulating time, such as making it appear to move backward or
advance too quickly. For more details, refer to the "Secure Nested Paging
(SEV-SNP)" section, subsection "Secure TSC" in APM Volume 2.

This patch set is also available at:

  https://github.com/AMDESE/linux-kvm/tree/sectsc-host-latest

and is based on kvm/master

Testing Secure TSC
-----------------

Secure TSC guest patches are available as part of v6.14-rc1.

QEMU changes:
https://github.com/nikunjad/qemu/tree/snp-securetsc-latest

QEMU command line SEV-SNP with Secure TSC:

  qemu-system-x86_64 -cpu EPYC-Milan-v2 -smp 4 \
    -object memory-backend-memfd,id=ram1,size=1G,share=true,prealloc=false,reserve=false \
    -object sev-snp-guest,id=sev0,cbitpos=51,reduced-phys-bits=1,secure-tsc=on,stsc-freq=2000000000 \
    -machine q35,confidential-guest-support=sev0,memory-backend=ram1 \
    ...

Changelog:
----------
v6:
* Rebased on top of kvm/master
* Collected Reviewed-by/Tested-by
* s/svm->vcpu/vcpu/ in snp_launch_update_vmsa() as vcpu pointer is already available (Tom)
* Simplify assignment of guest_protected_tsc (Tom)


v5: https://lore.kernel.org/kvm/20250317052308.498244-1-nikunj@amd.com/
* Rebased on top of kvm/queue that includes protected TSC patches
  https://lore.kernel.org/kvm/20250314183422.2990277-1-pbonzini@redhat.com/
* Dropped patch 4/5 as it is not required after protected TSC patches
* Set guest_tsc_protected when Secure TSC is enabled (Paolo)
* Collect Reviewed-by from Tom
* Base the desired_tsc_freq on KVM's ABI (Sean)

Ketan Chaturvedi (1):
  KVM: SVM: Enable Secure TSC for SNP guests

Nikunj A Dadhania (3):
  x86/cpufeatures: Add SNP Secure TSC
  KVM: SVM: Add missing member in SNP_LAUNCH_START command structure
  KVM: SVM: Add GUEST_TSC_FREQ MSR for Secure TSC enabled guests

 arch/x86/include/asm/cpufeatures.h |  1 +
 arch/x86/include/asm/svm.h         |  1 +
 arch/x86/include/uapi/asm/kvm.h    |  3 ++-
 arch/x86/kvm/svm/sev.c             | 18 +++++++++++++++++-
 arch/x86/kvm/svm/svm.c             |  1 +
 arch/x86/kvm/svm/svm.h             | 11 ++++++++++-
 include/linux/psp-sev.h            |  2 ++
 7 files changed, 34 insertions(+), 3 deletions(-)

----------------------------------------------------------------------

